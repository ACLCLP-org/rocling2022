<!DOCTYPE html>
<html lang="en">

<head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <title>Rocling2022</title>

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" type="text/css" href="assets/css/bootstrap.min.css">
    <!-- Icon -->
    <link rel="stylesheet" type="text/css" href="assets/fonts/line-icons.css">
    <!-- Slicknav -->
    <link rel="stylesheet" type="text/css" href="assets/css/slicknav.css">
    <!-- Nivo Lightbox -->
    <link rel="stylesheet" type="text/css" href="assets/css/nivo-lightbox.css">
    <!-- Animate -->
    <link rel="stylesheet" type="text/css" href="assets/css/animate.css">
    <!-- Main Style -->
    <link rel="stylesheet" type="text/css" href="assets/css/main.css">
    <!-- Responsive Style -->
    <link rel="stylesheet" type="text/css" href="assets/css/responsive.css">

</head>

<body>

    <!-- Header Area wrapper Starts -->
    <header id="header-wrap">
        <!-- Navbar Start -->
        <nav class="navbar navbar-expand-lg fixed-top scrolling-navbar">
            <div class="container">
                <!-- Brand and toggle get grouped for better mobile display -->
                <div class="navbar-header">
                    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#main-navbar"
                        aria-controls="main-navbar" aria-expanded="false" aria-label="Toggle navigation">
                        <span class="navbar-toggler-icon"></span>
                        <span class="icon-menu"></span>
                        <span class="icon-menu"></span>
                        <span class="icon-menu"></span>
                    </button>
                    <!-- <a href="index.html" class="navbar-brand"><img src="assets/img/logo.png" alt=""></a> -->
                </div>
                <div class="collapse navbar-collapse" id="main-navbar">
                    <ul class="navbar-nav mr-auto w-100 justify-content-end">
                        <li class="nav-item active">
                            <a class="nav-link pt20" href="#header-wrap">
                                Home
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link pt20" href="#about">
                                About
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link pt10" href="#gallery">
                                Call for Papers
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link pt20" href="#Programs">
                                Programs
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link pt10" href="#keynote-speakers">
                                Keynote Speakers
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link pt20" href="#DemoSession">
                                Demo Session
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link pt20" href="#pricing">
                                Registration
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link pt10" href="#specialSession">
                                Special Session
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link pt10" href="#sharedTask">
                                Shared Task
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link pt20" href="#organization">
                                Organization
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link pt20" href="#google-map-area">
                                Venue 
                            </a>
                        </li>
                    </ul>
                </div>
            </div>

            <!-- Mobile Menu Start -->
            <ul class="mobile-menu">
                <li>
                    <a class="page-scrool" href="#header-wrap">Home</a>
                </li>
                <li>
                    <a class="page-scrool" href="#about">About</a>
                </li>
                <li>
                    <a class="page-scroll" href="#gallery">Call for Papers</a>
                </li>
                <li>
                    <a class="page-scroll" href="#Programs">Programs</a>
                </li>
                <li>
                    <a class="page-scroll" href="#keynote-speakers">Keynote Speakers</a>
                </li>
                <li>
                    <a class="page-scroll" href="#DemoSession">Demo Session</a>
                </li>
                <li>
                    <a class="page-scroll" href="#pricing">Registration</a>
                </li>
                <li>
                    <a class="page-scroll" href="#specialSession">Special Session</a>
                </li>
                <li>
                    <a class="page-scroll" href="#organization">Organization</a>
                </li>
                <li>
                    <a class="page-scroll" href="#google-map-area">Contact</a>
                </li>
            </ul>
            <!-- Mobile Menu End -->

        </nav>
        <!-- Navbar End -->

        <!-- Main Carousel Section Start -->
        <div id="main-slide" class="carousel slide" data-ride="carousel">
            <ol class="carousel-indicators">
                <li data-target="#main-slide" data-slide-to="0" class="active"></li>
                <li data-target="#main-slide" data-slide-to="1"></li>
                <li data-target="#main-slide" data-slide-to="2"></li>
            </ol>
            <div class="carousel-inner">
                <div class="carousel-item active">
                    <img class="d-block w-100" src="assets/img/slider/slide1.jpg" alt="First slide">
                    <div class="carousel-caption d-md-block">
                        <p class="fadeInUp wow" data-wow-delay=".6s">Taipei Medical University, Daan Campus</p>
                        <h1 class="wow fadeInDown heading" data-wow-delay=".4s">the 34th Conference on Computational Linguistics and Speech Processing</h1>
                        <h3 class="fadeInUp wow" data-wow-delay=".6s">November 21 - 22 (Mon - Tue), 2022</h3>
                    </div>
                </div>
                <div class="carousel-item">
                    <img class="d-block w-100" src="assets/img/slider/slide2.jpg" alt="Second slide">
                    <div class="carousel-caption d-md-block">
                        <p class="fadeInUp wow" data-wow-delay=".6s">Taipei Medical University, Daan Campus</p>
                        <h1 class="wow bounceIn heading" data-wow-delay=".7s">the 34th Conference on Computational Linguistics and Speech Processing</h1>
                        <h3 class="fadeInUp wow" data-wow-delay=".6s">November 21 - 22 (Mon - Tue), 2022</h3>
                    </div>
                </div>
                <div class="carousel-item">
                    <img class="d-block w-100" src="assets/img/slider/slide3.jpg" alt="Third slide">
                    <div class="carousel-caption d-md-block">
                        <p class="fadeInUp wow" data-wow-delay=".6s">Taipei Medical University, Daan Campus</p>
                        <h1 class="wow fadeInUp heading" data-wow-delay=".6s">the 34th Conference on Computational Linguistics and Speech Processing</h1>
                        <h3 class="fadeInUp wow" data-wow-delay=".6s">November 21 - 22 (Mon - Tue), 2022</h3>
                    </div>
                </div>
            </div>
            <a class="carousel-control-prev" href="#main-slide" role="button" data-slide="prev">
                <span class="carousel-control" aria-hidden="true"><i class="lni-chevron-left"></i></span>
                <span class="sr-only">Previous</span>
            </a>
            <a class="carousel-control-next" href="#main-slide" role="button" data-slide="next">
                <span class="carousel-control" aria-hidden="true"><i class="lni-chevron-right"></i></span>
                <span class="sr-only">Next</span>
            </a>
        </div>
        <!-- Main Carousel Section End -->

    </header>
    <!-- Header Area wrapper End -->
    <!-- About Section Start -->
    <section id="about" class="section-padding">
      <div class="container">
        <div class="row">
          <div class="col-12">
            <div class="section-title-header text-center">
              <h1 class="section-title wow fadeInUp" data-wow-delay="0.2s">About</h1>
              <p class="wow fadeInDown" data-wow-delay="0.2s">Welcome to ROCLING 2022!</p>
            </div>
          </div>
        </div>
        <div class="row">
        <!--
          <div class="col-xs-12 col-md-6 col-lg-6">
            <div class="about-item">
              <img class="img-fluid" src="assets/img/about/img1.jpg" alt="">
              <div class="about-text">
                <h3><a href="#">ROCLING 2022 is going onsite</a></h3>
                <p>Our conference will be a live event with paper presentations and live participation.
                <br><br><br>
                </p>
              </div>
            </div>
          </div>
          <div class="col-xs-12 col-md-6 col-lg-6">
            <div class="about-item">
              <img class="img-fluid" src="assets/img/about/img2.jpg" alt="">
              <div class="about-text">
                <h3><a class="fontRed" href="https://rocling2022.github.io/ROCLING2022_SlideTemplate.pptx">Download Slide Template</a></h3>
                <p>We strongly suggest the authors using the ROCLING 2022 slide template to prepare their oral presentation. Please send us your presentation slide via the email <a href="mailto:rocling2022@gmail.com">rocling2022@gmail.com</a> by November 14.</p>
              </div>
            </div>
          </div>
          -->
          <div class="col-xs-12 col-md-6 col-lg-12 mt-30">
            <div class="about-item">
              <img class="img-fluid" src="assets/img/about/img3.jpg" alt="">
              <div class="about-text">
                <h3 class="Important"><a href="#">Important Dates</a></h3>
                <ul class="Important">
                  <li>Paper Submission Due: <del>September 3</del> September 10 (Sat), 2022 (final)</li>
                  <li>Notification of acceptance: September 30 (Fri), 2022</li>
                  <li>Camera-ready due: October 7 (Fri), 2022</li>
                  <li>Early Registration ends: October 14 (Fri), 2022</li>
                  <li>Late Registration ends: November 4 (Fri), 2022</li>
                  <li>On-Site Registration: November 21 - 22 (Mon - Tue), 2022</li>
                  <li>All deadlines are 11.59 pm UTC-12h (anywhere on earth)</li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- About Section End -->

    <section id="" class="section-padding">
      <div class="container">
        <div class="row">
          <div class="col-12">
            <div class="section-title-header text-center">
              <h1 class="section-title wow fadeInUp animated" data-wow-delay="0.2s" style="visibility: visible;-webkit-animation-delay: 0.2s; -moz-animation-delay: 0.2s; animation-delay: 0.2s;">Welcome to ROCLING 2022!</h1>
            </div>
          </div>
          <div class="col-md-6 col-lg-12 col-xs-12 wow fadeInRight animated" data-wow-delay="0.3s" style="visibility: visible;-webkit-animation-delay: 0.3s; -moz-animation-delay: 0.3s; animation-delay: 0.3s;">
            <div class="video">
              <img class="img-fluid" src="assets/img/about/rocling2022_history.jpg" alt="">
            </div>
          </div>
          <div class="col-md-6 col-lg-12 col-xs-12 wow fadeInLeft animated" data-wow-delay="0.3s" style="visibility: visible;-webkit-animation-delay: 0.3s; -moz-animation-delay: 0.3s; animation-delay: 0.3s;">
            <p class="intro-desc justify">ROCLING 2022 is the 34th annual Conference on Computational Linguistics and Speech Processing in Taiwan sponsored by the Association for Computational Linguistics and Chinese Language Processing (ACLCLP). The conference will be held in Taipei Medical University, Daan Campus, Taipei city, Taiwan during November 21-22, 2022.<br/><br/>ROCLING 2022 will provide an international forum for researchers and industry practitioners to share their new ideas, original research results and practical development experiences from all language and speech research areas, including computational linguistics, information understanding, and signal processing. ROCLING 2022 will feature oral papers, posters, tutorials, special sessions and shared tasks.<br/><br/>The conference on Computational Linguistics and Speech Processing (ROCLING) was initiated in 1988 by the Association for Computational Linguistics and Chinese Language Processing (ACLCLP) with the major goal to provide a platform for researchers and professionals from around the world to share their experiences related to natural language processing and speech processing. Following are a list of past ROCLING conferences.
            </p>
          </div>
        </div>
      </div>
    </section>

    <!-- Gallary Section Start -->
    <section id="gallery" class="section-padding">
        <div class="container">
            <div class="row">
                <div class="col-12">
                    <div class="section-title-header text-center">
                        <h1 class="section-title wow fadeInUp" data-wow-delay="0.2s">Call for Papers</h1>
                        <h2>Submission Guidelines</h2>
                    </div>
                </div>
            </div>
            <p class="justify">
                ROCLING 2022 invites paper submissions reporting original research results and system development experiences as well as real-world applications. Each submission will be reviewed based on originality, significance, technical soundness, and relevance to the conference. Accepted papers will be presented orally or as poster presentations. Both oral and poster presentations will be published in the ROCLING 2022 conference proceedings and included in the ACL Anthology. A number of papers will be selected and invited for extension into journal versions and publication in a special issue of the International Journal of Computational Linguistics and Chinese Language Processing (IJCLCLP).<br /><br />
                Papers can be written and presented in either Chinese or English. Papers should be made in PDF format and submitted online through the paper submission system. Submitted papers may consist of 4-8 pages of content, plus unlimited references. Upon acceptance, final versions will be given additional pages of content (up to 9 pages) so that reviewers’ comments can be taken into account. ROCLING 2022 mainly targets two scientific tracks: natural language processing (NLP) and speech processing (Speech).<br /><br />
                Relevant topics for the conference include, but are not limited to, the following areas (in alphabetical order):
            </p>
            <div class="blankDiv"></div>
            <div class="callForPapersCon flexBox">
                <div class="list01">
                    <h2>Natural Language Processing</h2>
                    <ul>
                        <li>Cognitive/Psychological Linguistics</li>
                        <li>Discourse and Pragmatics</li>
                        <li>Dialogue System</li>
                        <li>Information Extraction</li>
                        <li>Information Retrieval</li>
                        <li>Language Generation</li>
                        <li>Machine Translation</li>
                        <li>NLP Applications</li>
                        <li>Phonology, Morphology and Word Segmentation</li>
                        <li>Question Answering</li>
                        <li>Resources and Evaluation</li>
                        <li>Semantics: Lexical, Sentence-Level, Textual Inference</li>
                        <li>Sentiment Analysis</li>
                        <li>Summarization</li>
                        <li>Syntax: Tagging, Chunking and Parsing</li>
                        <li>Others</li>
                    </ul>
                </div>
                <div class="list02">
                    <h2>Speech Processing</h2>
                    <ul>
                        <li>Speech Perception, Production and Acquisition</li>
                        <li>Phonetics, Phonology and Prosody</li>
                        <li>Analysis of Paralinguistics in Speech and Language</li>
                        <li>Speaker and Language Identification</li>
                        <li>Analysis of Speech and Audio Signals</li>
                        <li>Speech Coding and Enhancement</li>
                        <li>Speech Synthesis and Spoken Language Generation</li>
                        <li>Speech Recognition</li>
                        <li>Spoken Dialog Systems and Analysis of Conversation</li>
                        <li>Spoken Language Processing: Retrieval, Translation, Summarization, Resources and Evaluation</li>
                        <li>Others</li>
                    </ul>
                </div>
            </div>
            <p class="justify">
                <br /><br />Paper submissions must use the official <a href="https://rocling2022.github.io/rocling2022-templates.zip">ROCLING 2022 style templates (Latex and Word).</a> Submission is electronic, using the EasyChair conference management system. The submission site is available at <a href="https://easychair.org/conferences/?conf=rocling2022">https://easychair.org/conferences/?conf=rocling2022</a><br /><br />
                As the reviewing will be double-blind, papers must not include authors' names and affiliations.
                Furthermore, self-references that reveal the author's identity must be avoided. Papers that do not conform to these requirements will be rejected without review. Papers may be accompanied by a resource (software and/or data) described in the paper, but these resources should be anonymized as well.
            </p>
            <div class="blankDiv"></div>
            <div class="callForPapersCon">
                <h2>Page Limitation - Camera-Ready Paper (applicable after acceptance)</h2>
                <p class="justify">According to the format of the paper template, the page limitations for accepted papers are 9 pages (plus unlimited references) in PDF format. The first page of the camera-ready version of the accepted paper should bear the items of paper title, author name, affiliation, and email address. All these items should be properly centered on the top, followed by a concise abstract of the paper.</p>
                <div class="blankDiv"></div>
                <h2>Copyright Form (applicable after acceptance) <a href="https://rocling2022.github.io/rocling2022_copyright.docx">download here</a></h2>
                <p class="justify">Every accepted paper should also be sent with a signed copyright form in PDF format via the online registration system.</p>
            </div>
        </div>
    </section>
    <!-- Gallary Section End -->




    <!-- Schedule Section Start -->
    <section id="Programs" class="schedule section-padding">
        <div class="container">
            <div class="row">
                <div class="col-12">
                    <div class="section-title-header text-center">
                        <h1 class="section-title wow fadeInUp" data-wow-delay="0.2s">Programs</h1>
                        <p class="wow fadeInDown" data-wow-delay="0.2s"><a
                                href="https://rocling2022.github.io/ROCLING2022_SlideTemplate.pptx">Download Slide Template</a></p>
                    </div>
                </div>
            </div>
            <div class="schedule-area row wow fadeInDown" data-wow-delay="0.3s">
                <div class="schedule-tab-title col-md-3 col-lg-3 col-xs-12">
                    <div class="table-responsive">
                        <ul class="nav nav-tabs" id="myTab" role="tablist">
                            <li class="nav-item">
                                <a class="nav-link active" id="monday-tab" data-toggle="tab" href="#monday" role="tab"
                                    aria-controls="monday" aria-expanded="true">
                                    <div class="item-text">
                                        <h4>Monday</h4>
                                        <h5>November 21, 2022</h5>
                                    </div>
                                </a>
                            </li>
                            <li class="nav-item">
                                <a class="nav-link" id="tuesday-tab" data-toggle="tab" href="#tuesday" role="tab"
                                    aria-controls="tuesday">
                                    <div class="item-text">
                                        <h4>Tuesday</h4>
                                        <h5>November 22, 2022</h5>
                                    </div>
                                </a>
                            </li>
                        </ul>
                    </div>
                </div>
                <div class="schedule-tab-content col-md-9 col-lg-9 col-xs-12 clearfix">
                    <div class="tab-content" id="myTabContent">
                        <div class="tab-pane fade show active" id="monday" role="tabpanel" aria-labelledby="monday-tab">
                            <div id="accordion">
                                <!--<p>Below, all information on the program of ROCLING 2022 are given that are available so far. More details to be announced.</p>-->
                                <div class="card">
                                    <div id="headingOne">
                                        <div class="collapsed card-header" data-toggle="collapse"
                                            data-target="#collapseOne" aria-expanded="false"
                                            aria-controls="collapseOne">
                                            <div class="images-box">
                                                <img class="img-fluid" src="assets/img/speaker/speakers-1.jpg" alt="">
                                            </div>
                                            <span class="time">08:50 - 09:00</span>
                                            <h4>Opening Ceremony</h4>
                                            <h5 class="name">(B201, B202)</h5>
                                        </div>
                                    </div>
                                </div>
                                <div class="card">
                                    <div id="headingTwo">
                                        <div class="collapsed card-header" data-toggle="collapse"
                                            data-target="#collapseTwo" aria-expanded="false"
                                            aria-controls="collapseTwo">
                                            <div class="images-box">
                                                <img class="img-fluid" src="assets/img/speaker/speakers-1.jpg" alt="">
                                            </div>
                                            <span class="time">09:00 - 10:00</span>
                                            <h4>Keynote: Matching Texts with Data for Evidence-based Information Retrieval, Prof. Makoto P. Kato</h4>
                                            <h5 class="name">(B201, B202)</h5>
                                        </div>
                                    </div>
                                </div>
                                <div class="card">
                                    <div id="headingThree">
                                        <div class="collapsed card-header" data-toggle="collapse"
                                            data-target="#collapseThree" aria-expanded="false"
                                            aria-controls="collapseThree">
                                            <div class="images-box">
                                                <img class="img-fluid" src="assets/img/speaker/speakers-3.jpg" alt="">
                                            </div>
                                            <span class="time">10:00 - 10:20</span>
                                            <h4>Coffee Break</h4>
                                            <h5 class="name">(B204)</h5>
                                        </div>
                                    </div>
                                </div>
                                <div class="card">
                                    <div id="headingThree">
                                        <div class="collapsed card-header" data-toggle="collapse"
                                            data-target="#collapseThree" aria-expanded="false"
                                            aria-controls="collapseThree">
                                            <div class="images-box">
                                                <img class="img-fluid" src="assets/img/speaker/speakers-1.jpg" alt="">
                                            </div>
                                            <span class="time">10:20 - 12:20</span>
                                            <table>
                                                <tr style="border: 0;">
                                                    <td width="400" style="border: 0;">
                                                        <h4>Session 1: Speech Application-1</h4>
                                                        <h5 class="name">(B205)</h5>
                                                        <h6><strong>Chair: Yi-Chin Huang</strong></h6>
                                                        <p>
                                                            <span class="time_s">(10:20 – 10:40)</span> Taiwanese-Accented Mandarin and English Multi-Speaker Talking-Face Synthesis System<br/>
                                                            <i>Chia-Hsuan Lin, Jian-Peng Liao, Cho-Chun Hsieh, Kai-Chun Liao and Chun-Hsin Wu</i><br/><br/>
                                                            <span class="time_s">(10:40 – 11:00)</span> Lightweight Sound Event Detection Model with RepVGG Architecture<br/>
                                                            <i>Chia-Chuan Liu, Sung-Jen Huang, Chia-Ping Chen, Chung-Li Lu, Bo-Cheng Chan, Yu-Han Cheng, Hsiang-Feng Chuang and Wei-Yu Chen</i><br/><br/>
                                                            <span class="time_s">(11:00 – 11:20)</span> A Preliminary Study on Automated Speaking Assessment of English as Second Language (ESL) Students <br/>
                                                            <i>Tzu-I Wu, Tien-Hong Lo, Fu-An Chao, Yao-Ting Sung and Berlin Chen</i><br/><br/>
                                                            <span class="time_s">(11:20 – 11:40)</span> Mandrin-English Code-Switching Speech Recognition System For Specific Domain 
                                                            <i>Chung-Pu Chiou, Hou-An Lin and Chia-Ping Chen</i><br/><br/>
                                                            <span class="time_s">(11:00 – 11:20)</span> A Preliminary Study on Automated Speaking Assessment of English as Second Language (ESL) Students <br/>
                                                            <i>Tzu-I Wu, Tien-Hong Lo, Fu-An Chao, Yao-Ting Sung and Berlin Chen</i><br/><br/>
                                                            <span class="time_s">(11:40 – 12:00)</span> MRight-Dominant Tones in Zhangzhou: On and Through Phonetic Surface 
                                                            <i>Jeng Man Lew, Li-Mei Chen and Yu Ching Lin</i><br/><br/>
                                                        </p>
                                                    </td>
                                                    <td style="border: 0; vertical-align:top;">
                                                        <h4>AI Tutorial I - AICup</h4>
                                                        <h5 class="name">(B201, B202)</h5>
                                                    </td>
                                                </tr>
                                            </table>
                                        </div>
                                    </div>
                                </div>
                                <div class="card">
                                    <div id="headingThree">
                                        <div class="collapsed card-header" data-toggle="collapse"
                                            data-target="#collapseThree" aria-expanded="false"
                                            aria-controls="collapseThree">
                                            <div class="images-box">
                                                <img class="img-fluid" src="assets/img/speaker/speakers-3.jpg" alt="">
                                            </div>
                                            <span class="time">12:20 - 13:00</span>
                                            <h4>Lunch</h4>
                                            <h5 class="name">(B204)</h5>
                                        </div>
                                    </div>
                                </div>
                                <div class="card">
                                    <div id="headingThree">
                                        <div class="collapsed card-header" data-toggle="collapse"
                                            data-target="#collapseThree" aria-expanded="false"
                                            aria-controls="collapseThree">
                                            <div class="images-box">
                                                <img class="img-fluid" src="assets/img/speaker/speakers-1.jpg" alt="">
                                            </div>
                                            <span class="time">13:00 - 13:30</span>
                                            <h4>ACLCLP Assembly</h4>
                                            <h5 class="name">(B201, B202)</h5>
                                        </div>
                                    </div>
                                </div>
                                <div class="card">
                                    <div id="headingThree">
                                        <div class="collapsed card-header" data-toggle="collapse"
                                            data-target="#collapseThree" aria-expanded="false"
                                            aria-controls="collapseThree">
                                            <div class="images-box">
                                                <img class="img-fluid" src="assets/img/speaker/speakers-1.jpg" alt="">
                                            </div>
                                            <span class="time">13:30 - 15:00</span>
                                            <table>
                                                <tr style="border: 0;">
                                                    <td width="400" style="border: 0;">
                                                        <h4>Shared Task: Chinese Healthcare Named Entity Recognition</h4>
                                                        <h5 class="name">(B205)</h5>
                                                        <h6><strong>Chair: Lung-Hao Lee</strong></h6>
                                                        <p>
                                                            <span class="time_s">(13:30 – 13:50)</span>  Overview of the ROCLING 2022 Shared Task for Chinese Healthcare Named Entity Recognition<br/>
                                                            <i>Lung-Hao Lee, Chao-Yi Chen, Liang-Chih Yu and Yuen-Hsien Tseng</i><br/><br/>
                                                            <span class="time_s">(1)</span> MIGBaseline at ROCLING 2022 Shared Task: Report on Named Entity Recognition Using Chinese Healthcare Datasets<br/>
                                                            <i>Hsing-Yuan Ma, Wei-Jie Li and Chao-Lin Liu</i><br/><br/>
                                                            <span class="time_s">(2)</span> SCU-MESCLab at ROCLING-2022 Shared Task: Named Entity Recognition Using BERT Classifier<br/>
                                                            <i>Tsung-Hsien Yang, Ruei-Cyuan Su, Tzu-En Su, Sing-Seong Chong and Ming-Hsiang Su</i><br/><br/>
                                                            <span class="time_s">(3)</span> CrowNER at Rocling 2022 Shared Task: NER using MacBERT and Adversarial Training<br/>
                                                            <i>Chiu-Hsia Chang, Te-Yu Chi, Te-Lun Yang and Jyh-Shing Jang</i><br/><br/>
                                                        </p>
                                                    </td>
                                                    <td style="border: 0;">
                                                        <h4>Nectar Program</h4>
                                                        <h5 class="name">(B201, B202)</h5>
                                                        <p>
                                                            <span class="time_s">(1)</span> SalesBot: Transitioning from Chit-Chat to Task-Oriented Dialogues, ACL 2022<br/>
                                                            <i>Ssu Chiu, Maolin Li, Yen-Ting Lin, Yun-Nung Chen</i><br/><br/>
                                                            <span class="time_s">(2)</span> Watanabe, Abdelrahman Mohamed, Hung-yi Lee, SUPERB-SG: Enhanced Speech processing Universal PERformance Benchmark for Semantic and Generative Capabilities, ACL 2022<br/>
                                                            <i>Hsiang-Sheng Tsai, Heng-Jui Chang, Wen-Chin Huang, Zili Huang, Kushal Lakhotia, Shu-wen Yang, Shuyan Dong, Andy Liu, Cheng-I Lai, Jiatong Shi, Xuankai Chang, Phil Hall, Hsuan-Jui Chen, Shang-Wen Li, Shinji Watanabe, Abdelrahman Mohamed, Hung-yi Lee</i><br/><br/>
                                                            <span class="time_s">(3)</span> Learning to Rank Visual Stories From Human Ranking Data, ACL 2022<br/>
                                                            <i>Chi-Yang Hsu, Yun-Wei Chu, Vincent Chen, Kuan-Chieh Lo, Chacha Chen, Ting-Hao Huang, Lun-Wei Ku</i><br/><br/>
                                                        </p>
                                                    </td>
                                                </tr>
                                            </table>
                                        </div>
                                    </div>
                                </div>
                                <div class="card">
                                    <div id="headingThree">
                                        <div class="collapsed card-header" data-toggle="collapse"
                                            data-target="#collapseThree" aria-expanded="false"
                                            aria-controls="collapseThree">
                                            <div class="images-box">
                                                <img class="img-fluid" src="assets/img/speaker/speakers-3.jpg" alt="">
                                            </div>
                                            <span class="time">15:00 - 15:30</span>
                                            <h4>Coffee Break</h4>
                                            <h5 class="name">(B204)</h5>
                                        </div>
                                    </div>
                                </div>
                                <div class="card">
                                    <div id="headingThree">
                                        <div class="collapsed card-header" data-toggle="collapse"
                                            data-target="#collapseThree" aria-expanded="false"
                                            aria-controls="collapseThree">
                                            <div class="images-box">
                                                <img class="img-fluid" src="assets/img/speaker/speakers-1.jpg" alt="">
                                            </div>
                                            <span class="time">15:30 - 17:30</span>
                                            <table>
                                                <tr style="border: 0;">
                                                    <td width="400" style="border: 0; vertical-align:top;">
                                                        <h4>Session 2: Best Paper Award Session</h4>
                                                        <h5 class="name">(B205)</h5>
                                                        <h6><strong>Chair: Yung-Chun Chang</strong></h6>
                                                        <p>
                                                            <span class="time_s">(15:30 – 16:00)</span> Unsupervised Text Summarization of Long Documents using Dependency-based Noun Phrases and Contextual Order Arrangement<br/>
                                                            <i>Yen-Hao Huang, Hsiao-Yen Lan and Yi-Shin Chen</i><br/><br/>
                                                            <span class="time_s">(16:00 – 16:30)</span> Is Character Trigram Overlapping Ratio Still the Best Similarity Measure for Aligning Sentences in a Paraphrased Corpus?<br/>
                                                            <i>Aleksandra Smolka, Hsin-Min Wang, Jason S. Chang and Keh-Yih Su</i><br/><br/>
                                                            <span class="time_s">(16:30 – 17:00)</span> Investigation of Feature Processing Modules and Attention Mechanisms in Speaker Verification System<br/>
                                                            <i>Ting-Wei Chen, Wei-Ting Lin, Chia-Ping Chen, Chung-Li Lu, Bo-Cheng Chan, Yu-Han Cheng, Hsiang-Feng Chuang and Wei-Yu Chen	</i><br/><br/>
                                                            <span class="time_s">(17:00 – 17:30)</span> Analyzing Discourse Functions with Acoustic Features and Phone Embeddings: Non-Lexical Items in Taiwan Mandarin<br/>
                                                            <i>Pin-Er Chen, Yu-Hsiang Tseng, Chi-Wei Wang, Fang-Chi Yeh and Shu-Kai Hsieh</i><br/><br/>
 
                                                        </p> 
                                                    </td>
                                                    <td style="border: 0;">
                                                        <h4>Poster</h4>
                                                        <h5 class="name">(B201, B202)</h5>
                                                        <p>
                                                            A Quantitative Analysis of Comparison of Emoji Sentiment: Taiwan Mandarin Users and English Users<br/>
                                                            <i>Fang Yu Chang</i><br/><br/>
                                                            Automatic Generation of Abstracts for Research Papers<br/>
                                                            <i>Dushan Kumarasinghe and Nisansa de Silva</i><br/><br/>
                                                            Chinese Movie Dialogue Question Answering Dataset<br/>
                                                            <i>Shang-Bao Luo, Hsin-Min Wang, Kuan-Yu Chen, Keh-Yih Su, Yu Tsao and Cheng-Chung Fan</i><br/><br/>
                                                            Enhancing Chinese Multi-Label Text Classification Performance with Response-based Knowledge Distillation<br/>
                                                            <i>Szu-Chi Huang, Cheng-Fu Cao, Po-Hsun Liao, Lung-Hao Lee, Po-Lei Lee and Kuo-Kai Shyu</i><br/><br/>
                                                            How to Ask and Answer a Robot About a Story Book<br/>
                                                            <i>Kai-Yen Kao and Chia-Hui Chang</i><br/><br/>
                                                            Image Caption Generation for Low-Resource Assamese Language<br/>
                                                            <i>Prachurya Nath, Prottay Kumar Adhikary, Pankaj Dadure, Partha Pakray, Riyanka Manna and Sivaji Bandyopadhyay</i><br/><br/>
                                                            Intelligent Future Recreation Harbor Application Service: Taking Kaohsiung Asia New Bay as an Example to Construct a Composite Recreational Knowledge Graph<br/>
                                                            <i>Chia Ming Tung, Bo Yang Huang, Dian Zhi Wu, Yu De Lu, Wen Hsiang Lu, Hsun Hui Huang and Chien Der Lin</i><br/><br/>
                                                            Multifaceted Assessments of Traditional Chinese Word Segmentation Tool on Large Corpora<br/><i>Wen-Chao Yeh, Yu-Lun Hsieh, Yung-Chun Chang and Wen-Lian Hsu</i><br/><br/>
                                                            The Design and Development of a System for Chinese Character Difficulty and Features<br/><i>Jung-En Haung, Hou-Chiang Tseng, Li-Yun Chang, Hsueh-Chih Chen and Yao-Ting Sung</i><br/><br/>
                                                            Using Machine Learning and Pattern-Based Methods for Identifying Elements in Chinese Judgment Documents of Civil Cases<br/><i>Hong-Ren Lin, Wei-Zhi Liu, Chao-Lin Liu and Chieh Yang</i><br/><br/>
                                                            Web-API-Based Chatbot Generation with Analysis and Expansion for Training Sentences<br/><i>Sheng-Kai Wang, Wan-Lin You and Shang-Pin Ma</i><br/><br/>
                                                            Legal Case Winning Party Prediction With Domain Specific Auxiliary Models<br/><i>Sahan Jayasinghe, Lakith Rambukkanage, Ashan Silva, Nisansa de Silva and Shehan Perera</i><br/><br/>
                                                            NCU1415 at ROCLING 2022 Shared Task: A light-weight transformer-based approach for Biomedical Name Entity Recognition<br/><i>Zhi-Quan Feng, Po-Kai Chen and Jia-Ching Wang</i><br/><br/>
                                                            NERVE at ROCLING 2022 Shared Task: A Comparison of Three Named Entity Recognition Frameworks Based on Language Model and Lexicon Approach<br/><i>Bo-Shau Lin, Jian-He Chen and Tao-Hsing Chang</i><br/><br/>
                                                            SCU-NLP at ROCLING 2022 Shared Task: Experiment and Error Analysis of Biomedical Entity Detection Model<br/><i>Sung-Ting Chiou, Sheng-Wei Huang, Ying-Chun Lo, Yu-Hsuan Wu and Jheng-Long Wu</i><br/><br/>
                                                            YNU-HPCC at ROCLING 2022 Shared Task: A Transformer-based Model with Focal Loss and Regularization Dropout for Chinese Healthcare Named Entity Recognition<br/><i>Xiang Luo, Jin Wang and Xuejie Zhang</i><br/><br/>
                                                        </p> 
                                                    </td>
                                                </tr>
                                            </table>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            <!-- END accordion-->
                        </div>
                        <div class="tab-pane fade" id="tuesday" role="tabpanel" aria-labelledby="tuesday-tab">
                            <div id="accordion2">
                                <!--<p>Below, all information on the program of ROCLING 2022 are given that are available so far. More details to be announced.</p>-->
                                <div class="card">
                                    <div id="headingOne1">
                                        <div class="collapsed card-header" data-toggle="collapse"
                                            data-target="#collapseOne1" aria-expanded="false"
                                            aria-controls="collapseOne1">
                                            <div class="images-box">
                                                <img class="img-fluid" src="assets/img/speaker/speakers-1.jpg" alt="">
                                            </div>
                                            <span class="time">09:00 - 10:00</span>
                                            <h4>Keynote: Speech Synthesis Research 2.0, Prof. Junichi Yamagishi</h4>
                                            <h5 class="name">(B201, B202)</h5>
                                        </div>
                                    </div>
                                </div>
                                <div class="card">
                                    <div id="headingOne1">
                                        <div class="collapsed card-header" data-toggle="collapse"
                                            data-target="#collapseOne1" aria-expanded="false"
                                            aria-controls="collapseOne1">
                                            <div class="images-box">
                                                <img class="img-fluid" src="assets/img/speaker/speakers-3.jpg" alt="">
                                            </div>
                                            <span class="time">10:00 - 10:20</span>
                                            <h4>Coffee Break</h4>
                                            <h5 class="name">(B204)</h5>
                                        </div>
                                    </div>
                                </div>
                                <div class="card">
                                    <div id="headingOne1">
                                        <div class="collapsed card-header" data-toggle="collapse"
                                            data-target="#collapseOne1" aria-expanded="false"
                                            aria-controls="collapseOne1">
                                            <div class="images-box">
                                                <img class="img-fluid" src="assets/img/speaker/speakers-1.jpg" alt="">
                                            </div>
                                            <span class="time">10:20 - 12:20</span>
                                            <table>
                                                <tr style="border: 0;">
                                                    <td width="400" style="border: 0;">
                                                        <h4>Session 3: Information Retrieval</h4>
                                                        <h5 class="name">(B205)</h5>
                                                        <h6><strong>Chair: Jheng-Long Wu</strong></h6>
                                                        <p>
                                                            <span class="time_s">(10:20 – 10:40)</span> Combining Word Vector Technique and Clustering Algorithm for Credit Card Merchant Detection<br/>
                                                            <i>Fang-Ju Lee, Ying-Chun Lo and Jheng-Long Wu</i><br/><br/>
                                                            <span class="time_s">(10:40 – 11:00)</span> RoBERTa-based Traditional Chinese Medicine Named Entity Recognition Model<br/>
                                                            <i>Ming-Hsiang Su, Chin-Wei Lee, Chi-Lun Hsu and Ruei-Cyuan Su</i><br/><br/>
                                                            <span class="time_s">(11:00 – 11:20)</span> Predicting Judgments and Grants for Civil Cases of Alimony for the Elderly<br/>
                                                            <i>Wei-Zhi Liu, Po-Hsien Wu, Hong-Ren Lin and Chao-Lin Liu</i><br/><br/>
                                                            <span class="time_s">(11:20 – 11:40)</span> A Dimensional Valence-Arousal-Irony Dataset for Chinese Sentence and Context<br/>
                                                            <i>Sheng-Wei Huang, Wei-Yi Chung, Yu-Hsuan Wu, Chen-Chia Yu and Jheng-Long Wu</i><br/><br/>
                                                            <span class="time_s">(11:40 – 12:00)</span> Building an Enhanced Autoregressive Document Retriever Leveraging Supervised Contrastive Learning<br/>
                                                            <i>Yi-Cheng Wang, Tzu-Ting Yang, Hsin-Wei Wang, Yung-Chang Hsu and Berlin Chen</i><br/><br/>
                                                            <span class="time_s">(12:00 – 12:20)</span> How to Ask and Answer a Robot About a Story Book<br/>
                                                            <i>How to Ask and Answer a Robot About a Story Book</i><br/><br/>
                                                        </p> 
                                                    </td>
                                                    <td style="border: 0; vertical-align:top;">
                                                        <h4>AI Tutorial II</h4>
                                                        <h5 class="name">(B201, B202)</h5>
                                                    </td>
                                                </tr>
                                            </table>
                                        </div>
                                    </div>
                                </div>
                                <div class="card">
                                    <div id="headingOne1">
                                        <div class="collapsed card-header" data-toggle="collapse"
                                            data-target="#collapseOne1" aria-expanded="false"
                                            aria-controls="collapseOne1">
                                            <div class="images-box">
                                                <img class="img-fluid" src="assets/img/speaker/speakers-3.jpg" alt="">
                                            </div>
                                            <span class="time">12:20 - 13:00</span>
                                            <h4>Lunch</h4>
                                            <h5 class="name">(B204)</h5>
                                        </div>
                                    </div>
                                </div>
                                <div class="card">
                                    <div id="headingOne1">
                                        <div class="collapsed card-header" data-toggle="collapse"
                                            data-target="#collapseOne1" aria-expanded="false"
                                            aria-controls="collapseOne1">
                                            <div class="images-box">
                                                <img class="img-fluid" src="assets/img/speaker/speakers-1.jpg" alt="">
                                            </div>
                                            <span class="time">13:00 - 15:00</span>
                                            <table>
                                                <tr style="border: 0;">
                                                    <td width="400" style="border: 0;">
                                                        <h4>Session 4: Speech Application-2</h4>
                                                        <h5 class="name">(B205)</h5>
                                                        <h6><strong>Chair: Yi-Fen Liu</strong></h6>
                                                        <p>
                                                            <span class="time_s">(13:00 – 13:20)</span> A Study on Using Different Audio Lengths in Transfer Learning for Improving Chainsaw Sound Recognition<br/>
                                                            <i>Jia-Wei Chang and Zhong-Yun Hu</i><br/><br/>
                                                            <span class="time_s">(13:20 – 13:40)</span> A Preliminary Study of the Application of Discrete Wavelet Transform Features in Conv-TasNet Speech Enhancement Model<br/>
                                                            <i>Yan-Tong Chen, Zong-Tai Wu and Jeih-Weih Hung</i><br/><br/>
                                                            <span class="time_s">(13:40 – 14:00)</span> Exploiting the Compressed Spectral Loss for the Learning of the DEMUCS Speech Enhancement Network<br/>
                                                            <i>Chi-En Dai, Qi-Wei Hong and Jeih-Weih Hung</i><br/><br/>
                                                            <span class="time_s">(14:00 – 14:20)</span> Development of Mandarin-English code-switching speech synthesis system<br/>
                                                            <i>Hsin-Jou Lien, Li-Yu Huang and Chia-Ping Chen</i><br/><br/>
                                                            <span class="time_s">(14:20 – 14:40)</span> Early Speech Production in Infants and Toddlers Later Diagnosed with Cerebral Palsy: A Retrospective Study<br/>
                                                            <i>Chien Ju Chan, Li-Mei Chen and Li-Wen Chen</i><br/><br/>
                                                            <span class="time_s">(14:40 – 15:00)</span> Speech Timing in Typically Developing Mandarin-Speaking Children From Ages 3 To 4<br/>
                                                            <i>Jeng Man Lew, Li-Mei Chen and Yu Ching Lin</i><br/><br/>
                                                        </p> 
                                                    </td>
                                                    <td style="border: 0; vertical-align:top;">
                                                        <h4>Thesis Award Session</h4>
                                                        <h5 class="name">(B201, B202)</h5>
                                                    </td>
                                                </tr>
                                            </table>
                                        </div>
                                    </div>
                                </div>
                                <div class="card">
                                    <div id="headingOne1">
                                        <div class="collapsed card-header" data-toggle="collapse"
                                            data-target="#collapseOne1" aria-expanded="false"
                                            aria-controls="collapseOne1">
                                            <div class="images-box">
                                                <img class="img-fluid" src="assets/img/speaker/speakers-3.jpg" alt="">
                                            </div>
                                            <span class="time">15:00 - 15:20</span>
                                            <h4>Coffee Break</h4>
                                            <h5 class="name">(B204)</h5>
                                        </div>
                                    </div>
                                </div>
                                <div class="card">
                                    <div id="headingOne1">
                                        <div class="collapsed card-header" data-toggle="collapse"
                                            data-target="#collapseOne1" aria-expanded="false"
                                            aria-controls="collapseOne1">
                                            <div class="images-box">
                                                <img class="img-fluid" src="assets/img/speaker/speakers-1.jpg" alt="">
                                            </div>
                                            <span class="time">15:20 - 17:20</span>
                                            <table>
                                                <tr style="border: 0;">
                                                    <td width="400" style="border: 0;">
                                                        <h4>Session 5: NLP Applications</h4>
                                                        <h5 class="name">(B205)</h5>
                                                        <h6><strong>Chair: Ming-Hsiang Su</strong></h6>
                                                        <p>
                                                            <span class="time_s">(15:20 – 15:40)</span> A Pattern-based News Summarization by Syntactic Structure and Verb Semantics<br/>
                                                            <i>Hsien-Hui Lee, Cheng-Wei Lin, Wen-Hsiang Lu and Chung-Ping Young</i><br/><br/>
                                                            <span class="time_s">(15:40 – 16:00)</span> Improving Response Diversity through Commonsense-Aware<br/>
                                                            <i>Empathetic Response Generation, Tzu-Hsien Huang and Chia-Hui Chang</i><br/><br/>
                                                            <span class="time_s">(16:00 – 16:20)</span> Language Model Based Chinese Handwriting Address Recognition<br/>
                                                            <i>Chieh-Jen Wang, Yung-Ping Tien and Yun-Wei Hung</i><br/><br/>
                                                            <span class="time_s">(16:20 – 16:40)</span> HanTrans: An Empirical Study on Cross-Era Transferability of Chinese Pre-trained Language Model<br/>
                                                            <i>Chin-Tung Lin and Wei-Yun Ma</i><br/><br/>
                                                            <span class="time_s">(16:40 – 17:00)</span> A Preliminary Study on Mandarin-Hakka Neural Machine Translation Using Small-Sized Data<br/>
                                                            <i>Yi-Hsiang Hung and Yi-Chin Huang</i><br/><br/>
                                                            <span class="time_s">(17:00 – 17:20)</span> Using Grammatical and Semantic Correction Model to Improve Chinese-to-Taiwanese Machine Translation Fluency<br/>
                                                            <i>Yuan-Han Li, Chung-Ping Young and Wen-Hsiang Lu</i><br/><br/>
                                                        </p> 
                                                    </td>
                                                    <td style="border: 0; vertical-align:top;">
                                                        <h4>Special Session: Construction and Application of Hakka Language Resources</h4>
                                                        <h5 class="name">(B201, B202)</h5>
                                                        <h6><strong>Chair: </strong></h6>
                                                        <p>
                                                            <span class="time_s"></span> 「臺灣客語語料庫」建置、現況與展望 (Taiwan Hakka Corpus: Construction, Current Development and Prospect)<br/>
                                                            <i>賴惠玲 教授</i><br/><br/>
                                                            <span class="time_s"></span> 口語對話與語音習得語料庫研究 (Corpus-based Research on Conversation Analysis and Speech Acquisition)<br/>
                                                            <i>曾淑娟 研究員兼副所長</i><br/><br/>
                                                        </p>  
                                                    </td>
                                                </tr>
                                            </table>
                                        </div>
                                    </div>
                                </div>
                                <div class="card">
                                    <div id="headingTwo2">
                                        <div class="collapsed card-header" data-toggle="collapse"
                                            data-target="#collapseTwo2" aria-expanded="false"
                                            aria-controls="collapseTwo2">
                                            <div class="images-box">
                                                <img class="img-fluid" src="assets/img/speaker/speakers-1.jpg" alt="">
                                            </div>
                                            <span class="time">17:20 - 17:30</span>
                                            <h4>Closing Ceremony</h4>
                                            <h5 class="name">(B201, B202)</h5>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
        </div>
    </section>
    <!-- PROGRAMS Section End -->

    <!-- KEYNOTE SPEAKERS Start -->
    <section id="keynote-speakers" class="section-padding">
        <div class="container">
            <div class="row pd15">
                <div class="col-12">
                    <div class="section-title-header text-center">
                        <h1 class="section-title wow fadeInUp" data-wow-delay="0.2s">KEYNOTE SPEAKERS</h1>
                        <p>More details to be announced.</p>
                    </div>
                </div>
                <div class="col-md-6 col-lg-6 col-xs-12 wow fadeInRight" data-wow-delay="0.3s">
                    <div class="video">
                        <img class="img-fluid" src="assets/img/keynoteSpeakers/keynoteSpeakers_MakotoPKato.jpg" alt="Prof. Makoto P. Kato">
                    </div>
                </div>
                <div class="col-md-6 col-lg-6 col-xs-12 wow fadeInLeft" data-wow-delay="0.3s">
                    <h2>Matching Texts with Data for Evidence-based Information Retrieval</h2>
                    <h2>Speaker: Prof. Makoto P. Kato</h2>
                    <div class="blankDiv"></div>
                    <ul class="list-specification">
                        <li><i class="lni-check-mark-circle"></i>Professor, University of Tsukuba, Japan</li>
                        <li><i class="lni-check-mark-circle"></i>Time: TBC</li>
                        <li><i class="lni-check-mark-circle"></i>Session Chair: TBC</li>
                    </ul>
                </div>
                <div class="blankDiv"></div>
                <h2>Biography</h2>
                <p class="justify">Makoto P. Kato received his Ph.D. degree in Graduate School of Informatics from Kyoto University, Sakyo Ward, Yoshidahonmachi, in 2012. Currently, he is an associate professor of Faculty of Library, Information and Media Science, University of Tsukuba, Japan. In 2008, he was awarded 'WISE 2008 Kambayashi Best Paper Award' through the article 'Can Social Tagging Improve Web Image Search?' with other researchers. In 2010, he served as a JSPS Research Fellow in Japan Society for the Promotion of Science. During the period 2010 to 2012, he also served in Microsoft Research Asia Internship (under supervision by Dr. Tetsuya Sakai in WIT group), Microsoft Research Asia Internship (under supervision by Dr. Tetsuya Sakai in WSM group), and Microsoft Research Internship (under supervision by Dr. Susan Dumais in CLUES group). From 2012, he worked as an assistant professor in Graduate School of Informatics, Kyoto University, Japan. His research and teaching career began, and he worked as an associate professor from 2019 in Graduate School of Informatics, Kyoto University, Japan. His research interests include Information Retrieval, Web Mining, and Machine Learning, while he is an associate professor in Knowledge Acquisition System Laboratory (Kato Laboratory), University of Tsukuba, Japan.</p>
                <div class="blankDiv"></div>
                <h2>Abstract</h2>
                <p class="justify">
                    We are now facing the problem of misinformation and disinformation on the Web, and search engines are struggling to retrieve reliable information from a vast amount of Web data. One of the possible solutions to this problem is to find reliable evidences supporting a claim on the Web. But what are “reliable evidences”? They can include authorities' opinions, scientific papers, or wisdom of crowds. However, they are also sometimes subjective as they are outcomes produced by people.<br/><br/>
                    This talk discusses some approaches incorporating another type of evidences that are very objective --- numerical data --- for reliable information access.<br/><br/>
                    (1) Entity Retrieval based on Numerical Attributes<br/>
                    Entity retrieval is a task of retrieving entities for a given text query and usually based on text matching between the query and entity description. Our recent work attempted to match the query and numerical attributes of entities and produce explainable rankings. For example, our approach ranks cameras based on their numerical attributes such as resolution, f-number, and weight, in response to queries such as “camera for astrophotography” and “camera for hiking”.<br/><br/>
                    (2) Data Search<br/>
                    When people encounter suspicious claims on the Web, data can be reliable sources for the fact checking. NTCIR Data Search is an evaluation campaign that aims to foster data search research by developing an evaluation infrastructure and organizing shared tasks for data search. The first test collection for data search and some findings are introduced in this talk.<br/><br/>
                    (3) Data Summarization<br/>
                    While the data search project attempts to develop a data search system for end users and help them make decisions based on data, it is still difficult for users to quickly interpret data. Therefore, data summarization techniques are also necessary to enable users to incorporate data in their information seeking process. Recent automatic visualization and text-based data summarization techniques are presented in this talk.
                </p>
                <div class="blankDiv"></div>
                <div class="theLine"></div>
                <div class="blankDiv"></div>
                <!--
                <div class="col-md-6 col-lg-6 col-xs-12 wow fadeInLeft" data-wow-delay="0.3s">
                    <h2>Title: (TBC)</h2>
                    <h2>Speaker: (TBC)</h2>
                    <div class="blankDiv"></div>
                    <ul class="list-specification">
                        <li><i class="lni-check-mark-circle"></i>TBC</li>
                        <li><i class="lni-check-mark-circle"></i>Time: TBC</li>
                        <li><i class="lni-check-mark-circle"></i>Session Chair: TBC</li>
                    </ul>
                </div>
                <div class="blankDiv"></div>
                <h2>Biography</h2>
                <p class="justify">TBC</p>
                <div class="blankDiv"></div>
                <h2>Abstract</h2>
                <p class="justify"> TBC </p>
                <div class="blankDiv"></div>
                <div class="theLine"></div>
                <div class="blankDiv"></div>
                -->
                <div class="col-md-6 col-lg-6 col-xs-12 wow fadeInRight" data-wow-delay="0.3s">
                    <div class="video">
                        <img class="img-fluid" src="assets/img/keynoteSpeakers/keynoteSpeakers_JunichiYamagishi.png" alt="Prof. Junichi Yamagishi">
                    </div>
                </div>
                <div class="col-md-6 col-lg-6 col-xs-12 wow fadeInLeft" data-wow-delay="0.3s">
                    <h2>Title: Speech Synthesis Research 2.0</h2>
                    <h2>Speaker: Prof. Junichi Yamagishi</h2>
                    <div class="blankDiv"></div>
                    <ul class="list-specification">
                        <li><i class="lni-check-mark-circle"></i>Professor, National Institute of Informatics, Japan</li>
                        <li><i class="lni-check-mark-circle"></i>Time: TBC</li>
                        <li><i class="lni-check-mark-circle"></i>Session Chair: TBC</li>
                    </ul>
                </div>
                <div class="blankDiv"></div>
                <h2>Biography</h2>
                <p class="justify">Junichi Yamagishi received the Ph.D. degree from Tokyo Institute of Technology in 2006 for a thesis that pioneered speaker-adaptive speech synthesis. He is currently a Professor with the National Institute of Informatics, Tokyo, Japan, and also a Senior Research Fellow with the Centre for Speech Technology Research, University of Edinburgh, Edinburgh, U.K. Since 2006, he has authored and co-authored more than 250 refereed papers in international journals and conferences. He was an area coordinator at Interspeech 2012. He was one of organizers for special sessions on “Spoofing and Countermeasures for Automatic Speaker Verification” at Interspeech 2013, “ASVspoof evaluation” at Interspeech 2015, “Voice conversion challenge 2016” at Interspeech 2016, “2nd ASVspoof evaluation” at Interspeech 2017, and “Voice conversion challenge 2018” at Speaker Odyssey 2018. He is currently an organizing committee for ASVspoof 2019, an organizing committee for ISCA the 10th ISCA Speech Synthesis Workshop 2019, a technical program committee for IEEE ASRU 2019, and an award committee for ISCA Speaker Odyssey 2020. He was a member of IEEE Speech and Language Technical Committee. He was also an Associate Editor of the IEEE/ACM TRANSACTIONS ON AUDIO, SPEECH, AND LANGUAGE PROCESSING and a Lead Guest Editor for the IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING special issue on Spoofing and Countermeasures for Automatic Speaker Verification. He is currently a guest editor for Computer Speech and Language special issue on speaker and language characterization and recognition: voice modeling, conversion, synthesis and ethical aspects. He also serves as a chairperson of ISCA SynSIG currently. He was the recipient of the Tejima Prize as the best Ph.D. thesis of Tokyo Institute of Technology in 2007. He received the Itakura Prize from the Acoustic Society of Japan in 2010, the Kiyasu Special Industrial Achievement Award from the Information Processing Society of Japan in 2013, the Young Scientists’ Prize from the Minister of Education, Science and Technology in 2014, the JSPS Prize from Japan Society for the Promotion of Science in 2016, and Docomo mobile science award from Mobile communication fund in 2018.</p>
                <div class="blankDiv"></div>
                <h2>Abstract</h2>
                <p class="justify">The Yamagishi Laboratory at the National Institute of Informatics researches text-to-speech (TTS) and voice conversion (VC) technologies. Having achieved TTS and VC methods that reproduce human-level naturalness and speaker similarity, we introduce three challenging projects we are currently working on as the next phase of our research.<br /><br />
                    1) Rakugo speech synthesis [1]<br />
                    As an example of a challenging application of speech synthesis technology, especially an example of an entertainment application, we have concentrated on rakugo, a traditional Japanese performing art. We have been working on learning and reproducing the skills of a professional comic storyteller using speech synthesis. This project aims to achieve an "AI storyteller" that entertains listeners, entirely different from the conventional speech synthesis task, whose primary purpose is to convey information or answer questions. The main story of rakugo comprises conversations between characters, and various characters appear in the story. These characters are performed by a single rakugo storyteller, who changes their voice appropriately so the listeners can understand and entertain them. To reproduce such characteristics of rakugo voice by machine learning, performance data of rakugo and advanced modeling techniques are required. Therefore, we constructed a corpus of rakugo speech without any noise or audience sounds with the cooperation of an Edo-style rakugo performer and modeled this data using deep learning. In addition, we benchmarked our system by comparing the generated Rakugo speech with performances by Rakugo storytellers of different ranks (“Zenza/前座," “Futatsume/二つ目," and “Shinuchi/真打") through subjective evaluation.<br /><br />
                    
                    (2) Speech intelligibility enhancement [2]<br />
                    In remote communication, such as online conferencing, there are environmental background noises on both speaker and listener sides. Speech intelligibility enhancement is a technique to manipulate speech signals so as not to be masked by the noise on the listener's side while maintaining the volume. This is not a simple conversion task since "correct teacher data" does not exist. For this reason, deep learning has not been used in the past, and there has been no significant technological progress. However, various possible practical applications exist, such as intelligibility enhancement of station announcements. Therefore, we proposed a network structure called "iMetricGAN" and its learning method, in which complex and non-differentiable speech intelligibility and quality indexes are treated as output values of a discriminator in an adversarial generative network, the discriminator approximates the indexes and based on the approximated indexes, a generator is used to transform an input speech signal into an enhanced, easy-to-hear speech signal automatically. Subject experiments confirmed that this transformation significantly improves keyword recognition in noisy environments.<br /><br />
                    
                    (3) Speaker Anonymization [3, 4]<br />
                    Now that it is becoming easier to build speech synthesis systems that digitally clone someone’s voice using ‘found' data on social media, there is a need to mask the speaker information in speech and other sensitive attributes that are appropriate to be protected. This is a new research topic; it has not yet been clearly defined how speaker anonymization can be achieved. We proposed a speaker anonymization method that combines speech synthesis and speaker recognition technologies. Our approach decomposes speech into three pieces of information: prosody, phoneme information, and a speaker embedding vector called X-vector, which is standardly used in speaker recognition and anonymizes the individuality of a speaker by averaging only the X-vector with K speakers. A neural vocoder is used to re-synthesize high-quality speech waveform. We also introduce a speech database and evaluation metrics to compare speaker anonymization methods.<br /><br />
                    
                    Reference<br />
                    [1] Shuhei Kato, Yusuke Yasuda, Xin Wang, Erica Cooper, Shinji Takaki, Junichi Yamagishi "Modeling of Rakugo Speech and Its Limitations: Toward Speech Synthesis That Entertains Audiences,” IEEE Access, vol.8, pp.138149-138161, July 2020<br/>
                    [2] Haoyu Li, Junichi Yamagishi, “Multi-Metric Optimization Using Generative Adversarial Networks for Near-End Speech Intelligibility Enhancement,” IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol.29, pp.3000-3011, Sept 2021<br/>
                    [3] Fuming Fang, Xin Wang, Junichi Yamagishi, Isao Echizen, Massimiliano Todisco, Nicholas Evans, Jean-Francois Bonastre, “Speaker Anonymization Using X-vector and Neural Waveform Models,” 10th ISCA Speech Synthesis Workshop (SSW10), Sept 2019 <br/>
                    [4] Xiaoxiao Miao, Xin Wang, Erica Cooper, Junichi Yamagishi, Natalia Tomashenko, "Language-Independent Speaker Anonymization Approach using Self-Supervised Pre-Trained Models,” Odyssey 2022: The Speaker and Language Recognition Workshop, June 2022
                </p>
                <div class="blankDiv"></div>
                <div class="theLine"></div>
            </div>
        </div>
    </section>
    <!-- KEYNOTE SPEAKERS End -->

    <!-- DEMO SESSION Start -->
    <section id="DemoSession" class="section-padding">
        <div class="container">
            <div class="row">
                <div class="col-12">
                    <div class="section-title-header text-center">
                        <h1 class="section-title wow fadeInUp" data-wow-delay="0.2s">DEMO SESSION</h1>
                        <p class="wow fadeInDown" data-wow-delay="0.2s">
                            <a>More details to be announced.</a>
                        </p>
                    </div>
                </div>
            <!--
            <div class="gernalArtical session">
                <h1>AI Tutorial I</h1>
                <h2>Speech enhancement (from signal processing to machine learning solutions) and its applications
                    for assistive hearing technology</h2>
                <h2>Time: Friday, October 15, 2022, 10:30-12:30</h2>
                <h2>Speakers: Yu Tsao (曹昱), Syu Siang Wang (王緒翔)</h2><br>
                <h3>Abstract</h3>
                <p class="justify">The proportional increase in the elderly population and the inappropriate use of
                    portable audio devices have led to a rapid increase in incidents of hearing loss. Untreated
                    hearing loss can cause feelings of loneliness and isolation in the elderly and may lead to
                    learning difficulties in students. Over the past few years, our group has investigated the
                    application of machine learning and signal processing algorithms in FM assistive hearing
                    systems, hearing aids, and cochlear implants (CIs) to improve speech communication in
                    hearing-impaired patients and the subsequent enhancement in their quality of life. The
                    tremendous progress of hearing-assistive technologies has enabled many hearing-loss recipients
                    to enjoy a high level of speech perception in quiet conditions. However, speech intelligibility
                    in noisy conditions still remains a challenge.<br /><br />
                    Meanwhile, real-world environments always contain stationary and/or time-varying noises that are
                    collected together with speech signals by recording devices. These received signals inevitably
                    degrade the performance of human-human and human-machine interfaces and have been attracted
                    significant attention over the past years. To address this issue, an important front-end speech
                    process, namely speech enhancement, is exploited to improve voice quality and intelligibility
                    from noise-deteriorated clean speech. In addition, speech enhancement techniques extracting
                    clean components from noisy input are combined with various applications including hearing
                    assistive devices. In this tutorial, we are going to introduce conventional speech enhancement
                    methods, its idea, concepts, and performances, and following with deep-learning denoising
                    approaches. The applications for assistive hearing technology are then provided in the rest of
                    the course.</p>
            </div>
            <div class="theLine"></div>
            <div class="gernalArtical session">
                <h1>AI Tutorial II</h1>
                <h2>深度學習在教育科技上的應用（學術詞彙片語、雙語對應、文法推導、文法改錯、反向詞典、定義分類與導引詞）</h2>
                <h2>Time: Friday, October 15, 2022, 13:30-15:00, 15:30-17:00</h2>
                <h2>Speakers: 張俊盛、楊謦瑜、吳鑑城、白明弘、杜海倫、陳志杰、段凱文</h2><br>
                <h3>Abstract</h3>
                <ul>
                    <li>學術詞彙+片語：如何延伸 Paquot (2000) 的 Academic Keyword List，產生定義、翻譯、例句、片語。</li>
                    <li>雙語詞彙、文法對應：如何改善前世代統計式片語機器翻譯的詞彙對應、片語對應，文法規則對應。</li>
                    <li>語言學搜尋引擎：如何利用 Google Web 1T 和 UDN 新聞語料庫，搜尋英文、中文的 Pattern Grammar 的文法規則 (Hunston 2000)</li>
                    <li>文法改錯：如何突破 Grammarly 的限制，處理搭配錯誤。</li>
                    <li>反向詞典：產生詞典語意（英文、中文）定義的詞彙內嵌，以及相關英文寫作應用。</li>
                    <li>辭典定義分類：產生詞典語意（英文、中文）定義的語意分類，可以將劍橋英漢辭典和羅氏主題詞典（Roget's Thesaurus）、維基百科的 Wikidata 連結起來。</li>
                    <li>辭典導引詞：用辭典定義分類技術，產生兩組合理，一致性高的歧異詞導引詞：以劍橋英漢線上辭典為例。</li>
                </ul>
            </div>-->
            </div>
        </div>
    </section>
    <!-- DEMO SESSION End -->


    <!-- Register Start -->
    <section id="pricing" class="section-padding">
        <div class="container">
            <div class="row">
                <div class="col-12">
                    <div class="section-title-header text-center">
                        <h1 class="section-title wow fadeInUp" data-wow-delay="0.2s">Registration</h1>
                        <!--<p>More details to be announced.</p>-->
                    </div>
                </div>
            </div>
            <div class="row">
                <div class="col-lg-4 col-sm-6 col-xa-12 mb-3">
                    <div class="price-block-wrapper wow fadeInLeft" data-wow-delay="0.2s">
                        <div class="icon">
                            <i class="lni lni-bolt-alt"></i>
                        </div>
                        <div class="colmun-title">
                            <h2>Early Registration</h2>
                            <h5>(Before October 14, 2022)</h5>
                        </div>
                        <div class="price">
                            <h5>Regular</h5>
                        </div>
                        <div class="pricing-list">
                            <ul>
                                <li><i class="lni-check-mark-circle"></i><span class="text">ACLCLP Member:
                                        NT$ 4,000</span></li>
                                <li><i class="lni-check-mark-circle"></i><span class="text">ACLCLP Non-Member: NT$ 5,000</span></li>
                            </ul>
                        </div>
                        <div class="price">
                            <h5>Student</h5>
                        </div>
                        <div class="pricing-list">
                            <ul>
                                <li><i class="lni-check-mark-circle"></i><span class="text">ACLCLP Member: NT$ 1,500</span>
                                </li>
                                <li><i class="lni-check-mark-circle"></i><span class="text">ACLCLP Non-Member: NT$ 2,000</span></li>
                            </ul>
                        </div>
                        <div class="price">
                            <h5>Sponsors</h5>
                        </div>
                        <div class="pricing-list">
                            <ul>
                                <li><i class="lni-check-mark-circle"></i><span class="text">Free</span></li>
                            </ul>
                        </div>
                        <a class="btn btn-common">Closed</a>
                        <!--<a href="https://conference.iis.sinica.edu.tw/surl/rocling2022/reg"
                            class="btn btn-common" target="_blank">Register</a>-->
                    </div>
                </div>
                <div class="col-lg-4 col-sm-6 col-xa-12 mb-3">
                    <div class="price-block-wrapper wow fadeInLeft" data-wow-delay="0.2s">
                        <div class="icon">
                            <i class="lni lni-alarm-clock"></i>
                        </div>
                        <div class="colmun-title">
                            <h2>Late Registration</h2>
                            <h5>(October 15 ~ November 4, 2022)</h5>
                        </div>
                        <div class="price">
                            <h5>Regular</h5>
                        </div>
                        <div class="pricing-list">
                            <ul>
                                <li><i class="lni-check-mark-circle"></i><span class="text">ACLCLP Member:
                                        NT$ 4,300</span></li>
                                <li><i class="lni-check-mark-circle"></i><span class="text">ACLCLP Non-Member: NT$ 5,300</span></li>
                            </ul>
                        </div>
                        <div class="price">
                            <h5>Student</h5>
                        </div>
                        <div class="pricing-list">
                            <ul>
                                <li><i class="lni-check-mark-circle"></i><span class="text">ACLCLP Member: NT$ 1,800</span>
                                </li>
                                <li><i class="lni-check-mark-circle"></i><span class="text">ACLCLP Non-Member: NT$ 2,300</span></li>
                            </ul>
                        </div>
                        <div class="price">
                            <h5>Sponsors</h5>
                        </div>
                        <div class="pricing-list">
                            <ul>
                                <li><i class="lni-check-mark-circle"></i><span class="text">Free</span></li>
                            </ul>
                        </div>
                        <!--<a class="btn btn-common">not yet open</a>-->
                        <a href="https://conference.iis.sinica.edu.tw/surl/rocling2022/reg" class="btn btn-common" target="_blank">Register</a>
                    </div>
                </div>
                <div class="col-lg-4 col-sm-6 col-xa-12 mb-3">
                    <div class="price-block-wrapper wow fadeInLeft" data-wow-delay="0.2s">
                        <div class="icon">
                            <i class="lni lni-flag-alt"></i>
                        </div>
                        <div class="colmun-title">
                            <h2>On-Site Registration</h2>
                            <h5>(November 21 - 22, 2022)</h5>
                        </div>
                        <div class="price">
                            <h5>Regular</h5>
                        </div>
                        <div class="pricing-list">
                            <ul>
                                <li><i class="lni-check-mark-circle"></i><span class="text">ACLCLP Member:
                                        NT$ 4,500</span></li>
                                <li><i class="lni-check-mark-circle"></i><span class="text">ACLCLP Non-Member: NT$ 5,500</span></li>
                            </ul>
                        </div>
                        <div class="price">
                            <h5>Student</h5>
                        </div>
                        <div class="pricing-list">
                            <ul>
                                <li><i class="lni-check-mark-circle"></i><span class="text">ACLCLP Member: NT$ 2,000</span>
                                </li>
                                <li><i class="lni-check-mark-circle"></i><span class="text">ACLCLP Non-Member: NT$ 2,500</span></li>
                            </ul>
                        </div>
                        <div class="price">
                            <h5>Sponsors</h5>
                        </div>
                        <div class="pricing-list">
                            <ul>
                                <li><i class="lni-check-mark-circle"></i><span class="text">Free</span></li>
                            </ul>
                        </div>
                        <a class="btn btn-common">not yet open</a>
                        <!--<a href="https://conference.iis.sinica.edu.tw/surl/rocling2022/reg"
                            class="btn btn-common" target="_blank">Register</a>-->
                    </div>
                </div>
                <div class="col-lg-12 col-sm-6 col-xa-12 mb-3">
                    <div class="price-block-wrapper wow fadeInLeft" data-wow-delay="0.2s">
                        <div class="icon">
                            <i class="lni lni-paperclip"></i>
                        </div>
                        <div class="colmun-title">
                            <h2>附註說明/Registration Fees</h2>
                        </div>
                        <div class="pricing-list">
                            <ul>
                                <li><i class="lni-check-mark-circle"></i><span
                                        class="text">每篇會議論文的發表至少要繳交一筆<b style="color:Red;">「一般人士 (Regular)」</b>報名費。</span></li>
                                <li><i class="lni-check-mark-circle"></i><span
                                        class="text">報名費含大會紀念品、午餐、茶點及晚宴，報名費一經繳費後恕不接受退費，會後將郵寄相關資料予報名者。</span></li>
                                <li><i class="lni-check-mark-circle"></i><span class="text">ACLCLP Member 為「中華民國計算語言學學會」之<b>有效會員</b>。</span></li>
                                <li><i class="lni-check-mark-circle"></i><span
                                        class="text">本年度<b>尚未繳交年費之舊會員或失效之會員</b>，與會身份/Category請勾選「….(會員+會費)」，<b>勿再重複申請入會</b>。</span>
                                </li>
                                <li><i class="lni-check-mark-circle"></i>
                                    <span class="text">
                                        <b>非會員欲同時申請入會者</b>，請先至學會網頁之「會員專區」申請加入會員；報名時「與會身份/Category」請勾選「….(會員+會費)」。
                                        <a href="http://www.aclclp.org.tw/member/index.php" target="_blank">
                                            (前往會員專區)
                                        </a>
                                    </span>
                                </li>
                                <li><i class="lni-check-mark-circle"></i><span
                                        class="text">以「學生新會員」及「學生非會員」身份報名者，請於報名時上傳學生身份證明。</span></li>
                                <li><i class="lni-check-mark-circle"></i><span
                                        class="text">贊助單位敬請於 <b style="color:Red;">11/4</b> 前完成報名手續。</span></li>
                                <li><i class="lni-check-mark-circle"></i><span class="text">報名費收據將於會議當日報到時交付。</span></li>
                                <!--<li><i class="lni-check-mark-circle"></i><span
                                        class="text">報名完成後，若需更正個人資料，請於 11/11 前以Email方式聯絡大會。</span></li>-->
                            </ul>
                        </div>
                        <div class="colmun-title">
                            <h2>Registration Details</h2>
                        </div>
                        <div class="pricing-list">
                            <ul>
                                <li><i class="lni-check-mark-circle"></i><span class="text">At least one author each paper has to pay a full registration.</span>
                                </li>
                                <li><i class="lni-check-mark-circle"></i><span class="text">Registration fee includes: abstract booklet, lunches, coffee breaks, and banquet.  <b>Registration fees are non-refundable.</b></span></li>
                                <li><i class="lni-check-mark-circle"></i><span class="text">International registrants have to pay by credit card only (Visa or MasterCard). Receipt will be provided on-site.</span>
                                </li>
                                <li><i class="lni-check-mark-circle"></i><span class="text">A copy of a valid student ID must be uploaded into the system when registering as a student.</span></li>
                            </ul>
                        </div>
                        <div class="colmun-title">
                            <h2>報名及繳費期限/Important Dates for Registration</h2>
                        </div>
                        <div class="pricing-list">
                            <ul>
                                <li><i class="lni-check-mark-circle"></i><span class="text">Early
                                        Registration: 10/14(Fri)以前，報名費應於 10/21(Fri)前繳交。
                                        </span>
                                </li>
                                <li><i class="lni-check-mark-circle"></i><span class="text">Late
                                        Registration: 10/15 (Sat) 至 11/4 (Fri)，報名費應於 11/11 (Fri) 前繳交(報名費加收300元)，線上刷卡繳費者需於 11/4(Fri) 前完成繳費。
                                        </span>
                                </li>
                                <li><i class="lni-check-mark-circle"></i><span class="text">On-Site
                                        Registration: 11/4(Fri) 線上報名截止，擬參加者，請至大會現場報名(報名費加收500元)。
                                       </span>
                                </li>
                            </ul>
                        </div>
                        <div class="colmun-title">
                            <h2>Important Dates for Registration</h2>
                        </div>
                        <div class="pricing-list">
                            <ul>
                                <li><i class="lni-check-mark-circle"></i><span class="text">Early Registration due by October 14. Payment must be received before October 21.</span></li>
                                <li><i class="lni-check-mark-circle"></i><span class="text">Registration between October 15 and November 4. Payment must be received before November 4.</span>
                                </li>
                                <li><i class="lni-check-mark-circle"></i><span class="text">The registration site will be closed on November 4. After that, please register on-site.</span></li>
                            </ul>
                        </div>
                        <div class="colmun-title">
                            <h2>繳費方式/Methods of Payment</h2>
                        </div>
                        <div class="pricing-list">
                            <ul>
                                <li>
                                    <i class="lni-check-mark-circle"></i>
                                    <span class="text">郵政劃撥/Postal——戶名：中華民國計算語言學學會帳號 帳號：19166251——(同一單位多位報名者可合併劃撥，請於劃撥通訊欄中註明「ROCLING及註冊編號或報名者姓名」)。
                                    </span></li>
                                <li><i class="lni-check-mark-circle"></i><span class="text">線上刷卡繳費/credit card on-line。</span>
                                </li>
                            </ul>
                        </div>
                        <div class="colmun-title">
                            <h2>註冊費事宜/For registration inquiries, please contact</h2>
                        </div>
                        <div class="pricing-list">
                            <ul>
                                <li><i class="lni-check-mark-circle"></i><span class="text">聯絡人：何婉如 小姐（中華民國計算語言學學會/ACLCLP）</span></li>
                                <li><i class="lni-check-mark-circle"></i><span class="text">E-mail：aclclp@aclclp.org.tw</span></li>
                                <li><i class="lni-check-mark-circle"></i><span class="text">Phone Number: 02-27881638</span></li>
                            </ul>
                        </div>
                        <!--<a href=""
                            class="btn btn-common">Register</a>-->
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- Register End -->

    <!-- specialSession Start -->
    <section id="specialSession" class="section-padding">
        <div class="container">
            <div class="row">
                <div class="col-12">
                    <div class="section-title-header text-center">
                        <h1 class="section-title wow fadeInUp" data-wow-delay="0.2s">Special Session</h1>
                        <!--<p>More details to be announced.</p>-->
                    </div>
                </div>
                <div class="gernalArtical session">
                    <h1>客語語言資源之建置與應用</h1>
                    <h2>Special Session: Construction and Application of Hakka Language Resources</h2>
                    <div class="blankDiv"></div>
                    <div class="row">
                        <div class="col-lg-4 col-md-6 col-xs-12">
                            <div class="blog-item">
                                <div class="blog-image">
                                    <a href="#">
                                        <img class="img-fluid" src="assets/img/specialsession/img-lai.png" alt="">
                                    </a>
                                </div>
                                <div class="descr">
                                    <div class="tag">賴惠玲</div>
                                    <h5>國立政治大學</h5>
                                    <div class="meta-tags">
                                        <span class="comments">英國語文學系特聘教授<br />hllai@nccu.edu.tw</span>
                                    </div>
                                    <h5>
                                        講題：「臺灣客語語料庫」建置、現況與展望 (Taiwan Hakka Corpus: Construction, Current Development and Prospect)
                                    </h5>
                                </div>
                            </div>
                        </div>
                        <div class="col-lg-4 col-md-6 col-xs-12">
                            <div class="blog-item">
                                <div class="blog-image">
                                    <a href="#">
                                        <img class="img-fluid" src="assets/img/specialsession/img-tseng.png" alt="">
                                    </a>
                                </div>
                                <div class="descr">
                                    <div class="tag">曾淑娟</div>
                                    <h5>中央研究院</h5>
                                    <div class="meta-tags">
                                        <span class="comments">語言學研究所研究員兼副所長<br />tsengsc@gate.sinica.edu.tw</span>
                                    </div>
                                    <h5>
                                        講題：口語對話與語音習得語料庫研究 (Corpus-based Research on Conversation Analysis and Speech Acquisition)
                                    </h5>
                                </div>
                            </div>
                        </div>
                        <!--<div class="col-lg-4 col-md-6 col-xs-12">
                            <div class="blog-item">
                                <div class="blog-image">
                                    <a href="#">
                                        <img class="img-fluid" src="assets/img/blog/img-1.jpg" alt="">
                                    </a>
                                </div>
                                <div class="descr">
                                    <div class="tag">李佳霖 Chia-lin Lee</div>
                                    <h5>國立台灣大學語言學研究所</h5>
                                    <div class="meta-tags">
                                        <span class="comments">Graduate Institute of Linguistics National Taiwan
                                            University, Taiwan<br />chialinlee@ntu.edu.tw</span>
                                    </div>
                                </div>
                            </div>
                        </div>-->
                    </div>
                    <!-- row End -->
                    <h3>摘要</h3>
                    <p class="justify">
                        依照語言學及語言科技的定義而言，在以語言運算為主的資料庫或應用平台中建立、維護與評測特定研究目的的語言材料，被稱為語言資源，其可大致分為語言語料與科技工具，前者包括文本、語詞、文法、語言模型或不同類型的語言資料，而後者為語言處理及維護。僅次於臺灣華語和臺灣閩南語，臺灣客語為第三大族群語言，又依客家委員會2017年的調查，符合《客家基本法》對客家人的定義「具有客家血緣或客家淵源，且自我認為為客家人者」，全國客家人口比例約有453.7萬人，占全國人口的19.3%，然而此調查亦顯示客家民眾聽說的能力是逐年下降，而客語的流失率卻是逐年上升。在拯救及保存瀕危語言的使命下，創建客語相關的語料庫或語言資源便是當務之急。本座談會匯集三位主要從事客語語料庫及相關研究的專家學者，由賴惠玲教授介紹及分享「臺灣客語語料庫」之建置過程與經驗，此語料庫為目前較具規模的大型客語語料庫，已克服客語建構中所面臨的諸多挑戰，亦開發客語的檢索及斷詞系統，迄今收錄客語口語語料（總共超過40萬字）與客語書面語料（總共超過600萬字）。其次，由廖元甫教授介紹及分享「臺灣客語語音庫」之蒐集過程與建置經驗，以客語AI語音辨識為目標，並針對客語四縣腔和海陸腔，廣泛錄製兩種客語的次方言語音，以及擴展語料的使用型態，期以做成客語語音合成及語言辨識的基礎。最後，由曾淑娟博士介紹及分享台灣華語成人及兒童語音語料庫研究經驗，以及客語對話的言談結構研究。
                    </p>
                    <div class="blankDiv"></div>
                    <h3>Abstract</h3>
                    <p class="justify">
                        According to the definition of Linguistics and language technology, a language resource is a linguistic material used in the construction, improvement and evaluation of language processing applications or platforms, which are roughly divided into linguistic data, including text, vocabulary, grammar, language models or different types of data, and technology tools, referring to language processing and maintenance. Next to Taiwan Mandarin Chinese and Taiwan Southern Min, Taiwan Hakka is the third largest language, and based on the Hakka Affairs Council's 2017 survey, the proportion of the Hakka population, in light of the definition of the Hakka Basic Law regarding Hakka people as "have Hakka blood or origin, and who believe themselves as Hakka people" is about 4.537 million, accounting for 19.3% of the national population. However, this survey also shows that the Hakka speaking and listening proficiency of Hakka people is declining, while the loss rate of the Hakka language is increasing. Under the mission of saving and preserving endangered languages, the creation of Hakka-related corpora or language resources is a top priority. This symposium brings together three experts and scholars who are mainly engaged in Hakka corpus and related research. Professor Huei-ling Lai introduces and shares the construction process and experience of the "Taiwan Hakka Corpus" (THC). Currently, the THC is a relatively large-scale Hakka corpus in a systematic manner. The THC construction has overcome various challenges derived from Hakka's idiosyncratic performance, and it has also developed a retrieval and word segmentation system for Hakka. So far, it has collected multiple Hakka spoken data (in total over 400,000 words) and Hakka written data (in total over 6 million words). Second, Professor Yuan-Fu Liao introduces and shares the collection process and construction experience of the "Taiwan Hakka Speech Database", aiming at widely collecting and recording the speech data of the two Hakka sub-dialects, Sixian dialect and Hailu dialect, for constructing the foundation of Hakka speech synthesis and AI speech recognition. Finally, Dr. Shu-Chuan Tseng introduces and shares her research on Taiwan Mandarin speech corpora of adults and children, as well as her recent works on discourse understanding of Hakka conversation.
                    </p>
                </div>
                <div class="theLine"></div>
            </div>
        </div>
    </section>
    <!-- specialSession End -->

    <!-- sharedTask Start -->
    <section id="sharedTask" class="section-padding">
        <div class="container">
            <div class="row">
                <div class="col-12">
                    <div class="section-title-header text-center">
                        <h1 class="section-title wow fadeInUp" data-wow-delay="0.2s">ROCLING 2022 Shared Task</h1>
                    </div>
                </div>
                <div class="gernalArtical session">
                    <h1>Chinese Healthcare Named Entity Recognition</h1>
                    <h2>Organizers</h2>
                    <div class="blankDiv"></div>
                    <div class="row">
                        <div class="col-lg-3 col-md-6 col-xs-12">
                            <div class="blog-item">
                                <div class="blog-image">
                                    <a href="#">
                                        <img class="img-fluid" src="assets/img/sharedTask/img-Lung-HaoLee.jpg" alt="">
                                    </a>
                                </div>
                                <div class="descr">
                                    <div class="tag">李龍豪 Lung-Hao Lee</div>
                                    <h5>國立中央大學電機工程學系</h5>
                                    <br />
                                    <div class="meta-tags">
                                        <span class="comments">Department of Electrical Engineering National Central University<br /><br />lhlee@ee.ncu.edu.tw<br /></span>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <div class="col-lg-3 col-md-6 col-xs-12">
                            <div class="blog-item">
                                <div class="blog-image">
                                    <a href="#">
                                        <img class="img-fluid" src="assets/img/sharedTask/img-Chao-YiChen.png" alt="Chao-Yi Chen">
                                    </a>
                                </div>
                                <div class="descr">
                                    <div class="tag">陳昭沂 Chao-Yi Chen</div>
                                    <h5>國立中央大學電機工程學系</h5>
                                    <br />
                                    <div class="meta-tags">
                                    <span class="comments">Department of Electrical Engineering National Central University<br /><br />110581007@cc.ncu.edu.tw<br /></span>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <div class="col-lg-3 col-md-6 col-xs-12">
                            <div class="blog-item">
                                <div class="blog-image">
                                    <a href="#">
                                        <img class="img-fluid" src="assets/img/sharedTask/img-Liang-ChihYu.png" alt="Liang-Chih Yu">
                                    </a>
                                </div>
                                <div class="descr">
                                    <div class="tag">禹良治 Liang-Chih Yu</div>
                                    <h5>元智大學資訊管理學系</h5>
                                    <br />
                                    <div class="meta-tags">
                                        <span class="comments">Department of Information Management Yuan Ze University<br /><br />lcyu@saturn.yzu.edu.tw<br /></span>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <div class="col-lg-3 col-md-6 col-xs-12">
                            <div class="blog-item">
                                <div class="blog-image">
                                    <a href="#">
                                        <img class="img-fluid" src="assets/img/sharedTask/img-Yuen-HsienTseng.png" alt="Yuen-Hsien Tseng">
                                    </a>
                                </div>
                                <div class="descr">
                                    <div class="tag">曾元顯 Yuen-Hsien Tseng</div>
                                    <h5>國立臺灣師範大學圖書資訊學研究所</h5>
                                    <div class="meta-tags">
                                        <span class="comments">Graduate Institute of Library and Information Studies National Taiwan Normal University<br />samtseng@ntnu.edu.tw</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                    <!-- row End -->
                    <div class="blankDiv"></div>
                    <h4>How to participate? Registration <a href="https://docs.google.com/forms/d/e/1FAIpQLSf17pTkYKzuDV7zkqhK4NvD5v6EnxlNRdfmmWNs3WcLtMMveA/viewform">here </a><small><a>(Due: August 20, 2022)</a></small></h4>
                    <div class="blankDiv"></div>
                    <h3>I. Background</h3>
                    <p class="justify">Named Entity Recognition (NER) is a fundamental task in information extraction that locates the mentions of named entities and classifies them (e.g., person, organization and location) in unstructured texts. The NER task has traditionally been solved as a sequence labeling problem, where entity boundaries and category labels are jointly predicted. Various methods have been proposed to tackle this research problem, including Hidden Markov Models (HMM) (Ponomareva et al., 2007), Maximum Entropy Markov Models (MEMM) (Chieu and Ng, 2003) and Conditional Random Field (CRF) (Wei et al., 2015). Recently, neural networks have been shown to achieve impressive results. The current state-of-the-art for English NER has been achieved by using LSTM (Long Short-Term Memory)- CRF based networks (Chiu and Nichols, 2016; Lample et al., 2016; Ma and Hovy, 2016; Liu et al., 2018). <br /><br />Chinese NER is more difficult to process than English NER. Chinese language is logographic and provides no conventional features like capitalization. In addition, due to a lack of delimiters between characters, Chinese NER is correlated with word segmentation, and named entity boundaries are also word boundaries. However, incorrectly segmented entity boundaries will cause error propagation in NER. For example, in a particular context, a disease entity “思覺失調症” (schizophrenia) may be incorrectly segmented into three words: “思覺” (thinking and feeling), “失調” (disorder) and “症” (disease). Hence, it has been shown that character-based methods outperform word-based approaches for Chinese NER (He and Wang, 2008; Li et al., 2014; Zhang and Yang, 2018).<br /><br/>In the digital era, healthcare information-seeking users usually search and browse web content in click-through trails to obtain healthcare-related information before making a doctor’s appointment for diagnosis and treatment. Web texts are valuable sources to provide healthcare information such as health-related news, digital health magazines and medical question/answer forums. Domain-specific healthcare information includes many proper names, mainly as named entities. For example, “三酸甘油酯” (triglyceride) is a chemical found in the human body; “電腦斷層掃描” (computed tomography; CT) is medical imaging procedure that uses computer-processed combinations of X-ray measurements to produce tomographic images of specific areas of the human body, and “靜脈免疫球蛋白注射” (intravenous immunoglobulin; IVIG) is a kind of treatment for avoiding infections. In summary, Chinese healthcare NER is an important and essential task in natural language processing to automatically identify healthcare entities such as symptoms, chemicals, diseases, and treatments for machine reading and understanding. </p>
                    <div class="blankDiv"></div>
                    <!--<div class="sharedTask_01"><img src="assets/img/sharedTask/sharedTask_01.png"></div>
                    <div class="blankDiv"></div>-->
                    <h3>II. Task Description</h3>
                    <p class="justify">A total of 10 entity types are described and some examples are provided in Table I for Chinese healthcare named entity recognition. In this task, participants are asked to predict the named entity boundaries and categories for each given sentence. We use the common BIO (Beginning, Inside, and Outside) format for NER tasks. The B-prefix before a tag indicates that the character is the beginning of a named entity and I-prefix before a tag indicates that the character is inside a named entity. An O tag indicates that a token belongs to no named entity. Below are the example sentences.<br /><br />Example 1:<br />
                        ●	Input: 修復肌肉與骨骼最重要的便是熱量、蛋白質與鈣質。<br />
                        ●	Output: O, O, B-BODY, I-BODY, O, B-BODY, I-BODY, O, O, O, O, O, O, O, O, O, B-CHEM, I-CHEM, I-CHEM, O, B-CHEM, I-CHEM, O
                    <br /><br />Example 2:<br />
                        ●	Input: 如何治療胃食道逆流症？<br />
                        ●	Output: O, O, O, O, B-DISE, I-DISE, I-DISE, I-DISE, I-DISE, I-DISE, O
                    </p>
                    <br/>
                    <p>Table 1. Named Entity Types with Descriptions and Examples</p>
                    <table>
                        <tr>
                            <td><b>Entity Type</b></td>
                            <td><b>Description</b></td>
                            <td><b>Examples</b></td>
                        </tr>
                        <tr>
                            <td>Body (BODY)</td>
                            <td>The whole physical structure that forms a person or animal including biological cells, organizations, organs and systems.</td>
                            <td>“細胞核” (nucleus), “神經組織” (nerve tissue), “左心房” (left atrium),  “脊髓” (spinal cord), “呼吸系統” (respiratory system)</td>
                        </tr>
                        <tr>
                            <td>Symptom (SYMP)</td>
                            <td>Any feeling of illness or physical or mental change that is caused by a particular disease.</td>
                            <td>“流鼻水” (rhinorrhea), “咳嗽” (cough), “貧血” (anemia), “失眠” (insomnia), “心悸” (palpitation), “耳鳴” (tinnitus)</td>
                        </tr>
                        <tr>
                            <td>Instrument (INST)</td>
                            <td>A tool or other device used for performing a particular medical task such as diagnosis and treatments.</td>
                            <td>“血壓計” (blood pressure meter), “達文西手臂” (DaVinci Robots), “體脂肪計” (body fat monitor), “雷射手術刀” (laser scalpel) </td>
                        </tr>
                        <tr>
                            <td>Examination (EXAM)</td>
                            <td>The act of looking at or checking something carefully in order to discover possible diseases.</td>
                            <td>“聽力檢查” (hearing test), “腦電波圖” (electroencephalography; EEG),  “核磁共振造影” (magnetic resonance imaging; MRI) </td>
                        </tr>
                        <tr>
                            <td>Chemical (CHEM)</td>
                            <td>Any basic chemical element typically found in the human body.</td>
                            <td>“去氧核糖核酸” (deoxyribonucleic acid; DNA), “糖化血色素” (glycated hemoglobin), “膽固醇” (cholesterol), “尿酸” (uric acid) </td>
                        </tr>
                        <tr>
                            <td>Disease (DISE)</td>
                            <td>An illness of people or animals caused by infection or a failure of health rather than by an accident.</td>
                            <td>“小兒麻痺症” (poliomyelitis; polio), “帕金森氏症” (Parkinson’s disease), “青光眼” (glaucoma), “肺結核” (tuberculosis) </td>
                        </tr>
                        <tr>
                            <td>Drug (DRUG)</td>
                            <td>Any natural or artificially made chemical used as a medicine</td>
                            <td>“阿斯匹靈” (aspirin), “普拿疼” (acetaminophen), “青黴素” (penicillin), “流感疫苗” (influenza vaccination)</td>
                        </tr>
                        <tr>
                            <td>Supplement (SUPP)</td>
                            <td>Something added to something else to improve human health.</td>
                            <td>“維他命” (vitamin), “膠原蛋白” (collagen), “益生菌” (probiotics), “葡萄糖胺” (glucosamine), “葉黃素” (lutein)</td>
                        </tr>
                        <tr>
                            <td>Treatment (TREAT)</td>
                            <td>A method of behavior used to treat diseases</td>
                            <td>“藥物治療” (pharmacotherapy), “胃切除術” (gastrectomy), “標靶治療” (targeted therapy), “外科手術” (surgery)</td>
                        </tr>
                        <tr>
                            <td>Time (TIME)</td>
                            <td>Element of existence measured in minutes, days, years</td>
                            <td>“嬰兒期” (infancy), “幼兒時期” (early childhood), “青春期” (adolescence), “生理期” (on one’s period), “孕期” (pregnancy)</td>
                        </tr>
                    </table>
                    <div class="blankDiv"></div>
                    <h3>III. Data</h3>
                    <p class="justify">
                    ●	Training Set: <a href="https://github.com/NCUEE-NLPLab/Chinese-HealthNER-Corpus">Chinese HealthNER Corpus</a> (Lee and Lu, 2021)<br />
                        It includes 30,692 sentences with a total around 1.5 million characters or 91.7 thousand words. After manual annotation, we have 68,460 named entities across 10 entity types: body, symptom, instrument, examination, chemical, disease, drug, supplement, treatment, and time.<br /><br />
                    ●	Test set: at least 3,000 Chinese sentences will be provided for system performance evaluation.<br /><br />
                    The policy of this shared task is an open test. Participating systems are allowed to use other publicly available data for this shared task, but the use of other data should be specified in the final system description paper.</p>
                    <div class="blankDiv"></div>
                    <h3>IV. Evaluation</h3>
                    <p class="justify">The performance is evaluated by examining the difference between machine-predicted labels and human-annotated labels. We adopt standard precision, recall, and F1-score, which are the most typical evaluation metrics of NER systems at a character level. If the predicted tag of a character in terms of BIO format was completely identical with the gold standard, that is one of the defined BIO tags, the character in the testing instance was regarded as correctly recognized. Precision is defined as the percentage of named entities found by the NER system that are correct. Recall is the percentage of named entities present in the test set found by the NER system.</p>
                    <div class="blankDiv"></div>
                    <h3>V. Important Dates</h3>
                    <p class="justify">
                        <ul class="Important">
                            <li>● Release of training data: April 15, 2022</li>
                            <li>● Release of test data: August 31, 2022</li>
                            <li>● Testing results submission due: September 2, 2022</li>
                            <li>● Release of evaluation results: September 5, 2022</li>
                            <li>● System description paper due: September 20, 2022</li>
                            <li>● Notification of Acceptance: September 30, 2022</li>
                            <li>● Camera-ready deadline: October 7, 2022</li>
                        </ul>
                    </p>
                    <div class="blankDiv"></div>
                    <h3>References</h3>
                    <p class="justify">
                        <li>Hai Leong Chieu, and Hwee Tou Ng (2003). Named entity recognition with a maximum approach. In Proceedings of 7th Conference on Natural Language Learning (CoNLL’03), pp. 160–163.</li>
                        <li>Jason P. C. Chiu, and Eric Nichols (2016). Named entity recognition with bidirectional LSTM-CNNs. Transactions of the Association for Computational Linguistics, 4:357–370.</li>
                        <li>Jingzhou He, and Houfeng Wang (2008). Chinese named entity recognition and word segmentation based on character. In Proceedings of the 6th SIGHAN Workshop on Chinese Language Processing (SIGHAN’08), pp. 128–132.</li>
                        <li>Guillaume Lample, Miguel Ballesteros, Sandeep Subramanian, Kazuya Kawakami, and Chris Dyer (2016). Neural architectures for named entity recognition. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT’16), pp. 260–270.</li>
                        <li>Lung-Hao Lee, and Yi Lu (2021). Multiple Embeddings Enhanced Multi-Graph Neural Networks for Chinese Healthcare Named Entity Recognition. IEEE Journal of Biomedical and Health Informatics, 25(7): 2801- 2810.</li>
                        <li>Haibo Li, Masato Hagiwara, Qi Li, and Heng Ji (2014). Comparison of the impact of word segmentation on name tagging for Chinese and Japanese. In Proceedings of the 9th International Conference on Language Resources and Evaluation (LREC’14), pp. 2532–2536.</li>
                        <li>Liyuan Liu, Jingbo Shang, Xiang Ren, Frank F. Xu, Huan Gui, Jian Peng, and Jiawei Han (2018). Empower sequence labeling with task-aware neural language model. In Proceedings of the 32nd AAAI Conference on Artificial Intelligence (AAAI’18), pp. 5253–5260.</li>
                        <li>Xuezhe Ma and Eduard Hovy (2016). End-to-end sequence labeling via Bi-directional LSTM-CNNs-CRF. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL’16), pp. 1064–1074.</li>
                        <li>Natalia Ponomareva, Ferran. Pla, Antonio Molina, and Paolo Rosso (2007). Biomedical named entity recognition: A poor knowledge HMM-based approach. In Proceedings of the 12th International Conference on Applications of Natural Language to Information Systems (NLDB’07), pp. 382–387.</li>
                        <li>Chih-Hsuan Wei, Robert Leaman, and Zhiyong Lu (2015). SimConcept: A hybrid approach for simplifying composite named entities in biomedical text. IEEE Journal of Biomedical and Health Informatics, 19(4):1385–1391.</li>
                        <li>Yue Zhang, and Jie Yang (2018). Chinese NER using lattice LSTM. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (ACL’18), pp. 1554–1564.</li>
                    </p>
                </div>
                <div class="theLine"></div>
            </div>
        </div>
    </section>
    <!-- sharedTask End -->


    <!-- Organization Start -->
    <section id="organization" class="section-padding">
        <div class="container">
            <div class="row">
                <div class="col-12">
                    <div class="section-title-header text-center">
                        <h1 class="section-title wow fadeInUp" data-wow-delay="0.2s">Organization</h1>
                    </div>
                </div>
            </div>
            <div class="row organization">
                <div class="col-lg-6 col-sm-6 col-xa-12 mb-3">
                    <div class="price-block-wrapper wow fadeInLeft" data-wow-delay="0.2s">
                        <div class="colmun-title">
                            <h3>Honorary Chair</h3>
                        </div>
                        <div class="row">
                            <div class="photo">
                                <a href="https://www.tmu.edu.tw/Front/about/about3/Page.aspx?id=QtntyBGmS1k=" target="_blank">
                                    <img src="assets/img/organization/photo_Chien-HuangLin.png">
                                </a>
                            </div>
                            <ul>
                                <li class="name">Chien-Huang Lin</li>
                                <li>Taipei Medical University</li>
                            </ul>
                        </div>
                        <br>
                        <div class="colmun-title">
                            <h3>Conference Chairs</h3>
                        </div>
                        <div class="row">
                            <div class="photo">
                                <a href="https://nlp.tmu.edu.tw" target="_blank">
                                    <img src="assets/img/organization/photo_Yung-ChunChang.png">
                                </a>
                            </div>
                            <ul>
                                <li class="name">Yung-Chun Chang</li>
                                <li>Taipei Medical University</li>
                            </ul>
                        </div>
                        <div class="row">
                            <div class="photo">
                                <a href="https://cs.nptu.edu.tw/p/412-1111-10340-1.php?Lang=zh-tw" target="_blank">
                                    <img src="assets/img/organization/photo_Yi-ChinHuang.png">
                                </a>
                            </div>
                            <ul>
                                <li class="name">Yi-Chin Huang</li>
                                <li>National Pingtung University</li>
                            </ul>
                        </div>
                        <br>
                        <div class="colmun-title">
                            <h3>Program Chairs</h3>
                        </div>
                        <div class="row">
                            <div class="photo">
                                <a href="https://nlp.bigdata.scu.edu.tw" target="_blank">
                                    <img src="assets/img/organization/photo_Jheng-LongWu.png">
                                </a>
                            </div>
                            <ul>
                                <li class="name">Jheng-Long Wu</li>
                                <li>Soochow University </li>
                            </ul>
                        </div>
                        <div class="row">
                            <div class="photo">
                                <a href="https://sites.google.com/gm.scu.edu.tw/mesc-lab/" target="_blank">
                                    <img src="assets/img/organization/photo_Ming-HsiangSu.png">
                                </a>
                            </div>
                            <ul>
                                <li class="name">Ming-Hsiang Su</li>
                                <li>Soochow University</li>
                            </ul>
                        </div>
                        <br>
                        <div class="colmun-title">
                            <h3>Demo Chairs</h3>
                        </div>
                        <div class="row">
                            <div class="photo">
                                <a href="https://homepage.iis.sinica.edu.tw/pages/hhhuang/" target="_blank">
                                    <img src="assets/img/organization/photo_Hen-HsenHuang.png">
                                </a>
                            </div>
                            <ul>
                                <li class="name">Hen-Hsen Huang</li>
                                <li>Academia Sinica</li>
                            </ul>
                        </div>
                        <br>
                        <div class="colmun-title">
                            <h3>Publication Chair</h3>
                        </div>
                        <div class="row">
                            <div class="photo">
                                <a href="https://www.iecs.fcu.edu.tw/teacher/劉怡芬/" target="_blank">
                                    <img src="assets/img/organization/photo_Yi-FenLiu.png">
                                </a>
                            </div>
                            <ul>
                                <li class="name">Yi-Fen Liu</li>
                                <li>Feng Chia University</li>
                            </ul>
                        </div>
                        <br>
                        <div class="colmun-title">
                            <h3>Shared Task Chair</h3>
                        </div>
                        <div class="row">
                            <div class="photo">
                                <a href="https://www.lhlee.net" target="_blank">
                                    <img src="assets/img/organization/photo_Lung-HaoLee.png">
                                </a>
                            </div>
                            <ul>
                                <li class="name">Lung-Hao Lee</li>
                                <li>National Central University</li>
                            </ul>
                        </div>
                        <br>
                        <div class="colmun-title">
                            <h3>Special Session Chair</h3>
                        </div>
                        <div class="row">
                            <div class="photo">
                                <a href="http://hakka.ncu.edu.tw/Dean.aspx" target="_blank">
                                    <img src="assets/img/organization/photo_Chin-HungChou.png">
                                </a>
                            </div>
                            <ul>
                                <li class="name">Chin-Hung Chou</li>
                                <li>National Central University</li>
                            </ul>
                        </div>
                        <div class="row">
                            <div class="photo">
                                <a href="https://sites.google.com/site/speechlabx" target="_blank">
                                    <img src="assets/img/organization/photo_Yuan-FuLiao.png">
                                </a>
                            </div>
                            <ul>
                                <li class="name">Yuan-Fu Liao</li>
                                <li>Taipei Tech Electronic University</li>
                            </ul>
                        </div>
                        <!--<div class="row">
                            <div class="photo"><img src=""></div>
                            <ul>
                                <li class="name">Hsiang-Chien Liu</li>
                                <li>National Central University</li>
                            </ul>
                        </div>-->
                    </div>
                </div>
                <div class="col-lg-6 col-sm-6 col-xa-12 mb-3">
                    <div class="price-block-wrapper wow fadeInLeft" data-wow-delay="0.2s">
                        <div class="colmun-title">
                            <h3>Organized by</h3>
                        </div>
                        <div class="row">
                            <div class="photo logo col-lg-3">
                                <a href="https://www.tmu.edu.tw" target="_blank">
                                    <img src="assets/img/organization/logo_TMU.png">
                                </a>
                            </div>
                            <div class="logoName col-lg-9 pt30">
                                <!--<a href="https://www.tmu.edu.tw" target="_blank">-->
                                    Taipei Medical University
                                <!--</a>-->
                            </div>
                        </div>
                        <div class="row">
                            <div class="photo logo col-lg-3">
                                <a href="https://www.nptu.edu.tw/" target="_blank">
                                    <img src="assets/img/organization/logo_NPU.png">
                                </a>
                            </div>
                            <div class="logoName col-lg-9 pt25">
                                <!--<a href="https://www.nptu.edu.tw/" target="_blank">-->
                                    National Pingtung University
                                <!--</a>-->
                            </div>
                        </div>
                        <div class="row">
                            <div class="photo logo col-lg-3">
                                <a href="http://www.aclclp.org.tw" target="_blank">
                                    <img src="assets/img/organization/logo_03.png">
                                </a>
                            </div>
                            <div class="logoName col-lg-9 pt25">
                                The Association for Computational Linguistics and Chinese Language Processing
                            </div>
                        </div>
                        <!--
                        <div class="blankDiv"></div>
                        <div class="colmun-title">
                            <h3>Co-Organized by</h3>
                        </div>
                        <div class="coLogo"><img src="assets/img/organization/logoCo_01.png"></div>
                        <div class="coLogo"><img src="assets/img/organization/logoCo_02.png"></div>
                        -->
                        <div class="blankDiv"></div>
                        <div class="colmun-title">
                            <h3>Supported by</h3>
                        </div>
                        <div class="coLogo_sponsor">
                            <a href="https://www.nstc.gov.tw/" target="_blank">
                                <img src="assets/img/organization/logo_NSTC.png">
                            </a>
                        </div>
                        <br />
                        <div class="coLogo_sponsor">
                            <a href="https://www.edu.tw/" target="_blank">
                                <img src="assets/img/organization/logo_EDU.png">
                            </a>
                        </div>
                        <div class="blankDiv"></div>
                        <div class="colmun-title">
                            <h3>Sponsored by</h3>
                        </div>
                        <div class="coLogo_sponsor">
                            <a href="https://www.esunbank.com.tw/" target="_blank">
                                <img src="assets/img/sponsors/logo-esunfhc.png">
                            </a>
                        </div>
                        <br />
                        <div class="coLogo_sponsor">
                            <a href="https://www.cyberon.com.tw/" target="_blank">
                                <img src="assets/img/sponsors/logo-cyberon.png">
                            </a>
                        </div>
                        <br />
                        <div class="coLogo_sponsor">
                            <a href="https://www.chttl.com.tw/" target="_blank">
                                <img src="assets/img/sponsors/logo-ctl.png">
                            </a>
                        </div>
                        <br />
                        <div class="coLogo_sponsor">
                            <a href="https://www.deltaww.com/" target="_blank">
                                <img src="assets/img/sponsors/logo-delta.jpg">
                            </a>
                        </div>
                        <br />
                        <div class="coLogo_sponsor">
                            <a href="http://www.hhnet.com.tw/" target="_blank">
                                <img src="assets/img/sponsors/logo-hhnet.png">
                            </a>
                        </div>
                        <br />
                        <div class="coLogo_sponsor">
                            <a href="https://line.me/" target="_blank">
                                <img src="assets/img/sponsors/logo-line.png">
                            </a>
                        </div>
                        <br />
                        <div class="coLogo_sponsor">
                            <a href="https://www.eland.com.tw" target="_blank">
                                <img src="assets/img/sponsors/logo-eland.png">
                            </a>
                        </div>
                        <br />
                        <div class="coLogo_sponsor">
                            <a href="https://aif.tw/" target="_blank">
                                <img src="assets/img/sponsors/logo-aif.png">
                            </a>
                        </div>
                        <br />
                        <div class="coLogo_sponsor">
                            <a href="https://www.nchc.org.tw" target="_blank">
                                <img src="assets/img/sponsors/logo-nchc.png">
                            </a>
                        </div>
                        <br />
                        <div class="coLogo_sponsor">
                            <a href="https://iis.sinica.edu.tw/" target="_blank">
                                <img src="assets/img/sponsors/logo-iis.png">
                            </a>
                        </div>
                        <br />
                        <div class="coLogo_sponsor">
                            <a href="https://www.citi.sinica.edu.tw" target="_blank">
                                <img src="assets/img/sponsors/logo-citi.png">
                            </a>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- Organization End -->

    <!-- Map Section Start -->
    <section id="google-map-area" class="section-padding">
        <div class="container">
            <div class="row">
                <div class="col-12">
                    <div class="section-title-header text-center">
                        <h1 class="section-title wow fadeInUp" data-wow-delay="0.2s">VENUE</h1>
                    </div>
                </div>
            </div>
            <div class="row">
                <div class="col-lg-6">
                    <iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d3615.2309169194!2d121.54968332685112!3d25.026236393519593!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x3442aa348024c4c1%3A0x781b9b2f6555d6ac!2sTMU%20Daan%20Campus!5e0!3m2!1sen!2sid!4v1660879810765!5m2!1sen!2sid" width="400" height="300" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade">
                    </iframe>
                </div>
                <div class="col-lg-6 mapDetail">
                    <ul>
                        <li>
                            <h5>臺北醫學大學，大安校區<br/>Taipei Medical University, Daan Campus</h5>
                        </li>
                        <li>Phone: 02-6638-2736</li>
                        <li>Google Map: 
                            <a href="https://goo.gl/maps/9Vwn3XwCG17Q1zbB9" target="_blank">
                                https://goo.gl/maps/9Vwn3XwCG17Q1zbB9
                            </a>
                        </li>
                        <li>Address: 106 臺北市大安區基隆路二段172-1號</li>
                        <li>Conference Room: B201</li>
                        <li>Contact Us: <a href="mailto:rocling2021@gmail.com">rocling2022@gmail.com</a></li>
                    </ul>
                </div>
            </div>
        </div>
    </section>
    <!-- Map Section End -->

    <!-- Counter Area Start-->
    <section class="counter-section section-padding">
        <div class="container">
            <div class="row">
                <!-- Counter Item -->
                <div class="col-md-6 col-lg-3 col-xs-12 work-counter-widget text-center">
                    <div class="counter wow fadeInRight" data-wow-delay="0.3s">
                        <div class="icon"><i class="lni-map"></i></div>
                        <p>Rocling2022</p>
                        <span>Taipei city, Taiwan</span>
                    </div>
                </div>
                <!-- Counter Item -->
                <div class="col-md-6 col-lg-3 col-xs-12 work-counter-widget text-center">
                    <div class="counter wow fadeInRight" data-wow-delay="0.6s">
                        <div class="icon"><i class="lni-timer"></i></div>
                        <p>November 21 - 22, 2022</p>
                        <span>09:00 AM – 05:00 PM</span>
                    </div>
                </div>
                <!-- Counter Item -->
                <div class="col-md-6 col-lg-3 col-xs-12 work-counter-widget text-center">
                    <div class="counter wow fadeInRight" data-wow-delay="0.9s">
                        <div class="icon"><i class="lni-users"></i></div>
                        <p>343 Available Seats</p>
                        <span>Hurryup! few tickets are left</span>
                    </div>
                </div>
                <!-- Counter Item -->
                <div class="col-md-6 col-lg-3 col-xs-12 work-counter-widget text-center">
                    <div class="counter wow fadeInRight" data-wow-delay="1.2s">
                        <div class="icon"><i class="lni-coffee-cup"></i></div>
                        <p>Free Lunch & Snacks</p>
                        <span>Don’t miss it</span>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- Counter Area End-->

    <div id="copyright">
        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <div class="site-info">
                        <p>©ROCLING 2022,Taipei Medical University(TMU), Taipei city,Taiwan || Email: 
                            <a href="mailto:rocling2022@gmail.com">
                                rocling2022@gmail.com
                            </a> || Updated: October 13, 2022
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- Go to Top Link -->
    <a href="#" class="back-to-top">
        <i class="lni-chevron-up"></i>
    </a>

    <div id="preloader">
        <div class="sk-circle">
            <div class="sk-circle1 sk-child"></div>
            <div class="sk-circle2 sk-child"></div>
            <div class="sk-circle3 sk-child"></div>
            <div class="sk-circle4 sk-child"></div>
            <div class="sk-circle5 sk-child"></div>
            <div class="sk-circle6 sk-child"></div>
            <div class="sk-circle7 sk-child"></div>
            <div class="sk-circle8 sk-child"></div>
            <div class="sk-circle9 sk-child"></div>
            <div class="sk-circle10 sk-child"></div>
            <div class="sk-circle11 sk-child"></div>
            <div class="sk-circle12 sk-child"></div>
        </div>
    </div>

    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="assets/js/jquery-min.js"></script>
    <script src="assets/js/popper.min.js"></script>
    <script src="assets/js/bootstrap.min.js"></script>
    <script src="assets/js/jquery.countdown.min.js"></script>
    <script src="assets/js/jquery.nav.js"></script>
    <script src="assets/js/jquery.easing.min.js"></script>
    <script src="assets/js/wow.js"></script>
    <script src="assets/js/jquery.slicknav.js"></script>
    <script src="assets/js/nivo-lightbox.js"></script>
    <script src="assets/js/main.js"></script>
    <script src="assets/js/form-validator.min.js"></script>
    <script src="assets/js/contact-form-script.min.js"></script>
    <script src="assets/js/map.js"></script>
    <!--   <script type="text/javascript" src="//maps.googleapis.com/maps/api/js?key=AIzaSyCsa2Mi2HqyEcEnM1urFSIGEpvualYjwwM"></script> -->

</body>

</html>
